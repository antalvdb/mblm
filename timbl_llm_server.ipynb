{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5ypeoUloZ2BXivUDgQtWh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antalvdb/mblm/blob/main/timbl_llm_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import re\n",
        "import time\n",
        "import argparse\n",
        "import sys"
      ],
      "metadata": {
        "id": "W3ElZ4BNsdKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python3-timbl\n",
        "\n",
        "import timbl"
      ],
      "metadata": {
        "id": "SspA9rKassIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global verbosity level\n",
        "VERBOSITY = 3"
      ],
      "metadata": {
        "id": "_DDg3l-atTDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_prompt(words, max_len=16):\n",
        "    \"\"\"Pad or trim the list of words to make it exactly `max_len` words.\"\"\"\n",
        "    if words is None:\n",
        "        words = []  # Ensure words is a list\n",
        "    if len(words) < max_len:\n",
        "        words = ['_'] * (max_len - len(words)) + words\n",
        "    else:\n",
        "        words = words[-max_len:]\n",
        "    return words"
      ],
      "metadata": {
        "id": "aorFqUootV-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h79ofJcqHDq"
      },
      "outputs": [],
      "source": [
        "def generate_text_from_server(host, port, initial_prompt, max_words=200):\n",
        "\n",
        "    # Tokenize the initial prompt and convert tokens back to words\n",
        "    initial_tokens = tokenizer.tokenize(initial_prompt)\n",
        "\n",
        "    if initial_tokens is None:\n",
        "        print(\"Tokenization failed; 'initial_tokens' is None.\")\n",
        "        initial_tokens = []\n",
        "\n",
        "    # Prepare the initial prompt, padded or trimmed to 8 words\n",
        "    prompt_words = pad_prompt(initial_tokens)\n",
        "\n",
        "    generated_tokens = prompt_words[:]  # Store the full generated text\n",
        "\n",
        "    try:\n",
        "        # Create a socket connection\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as client_socket:\n",
        "            # Connect to the server\n",
        "            client_socket.connect((host, port))\n",
        "\n",
        "            # Receive the initial \"Welcome\" message from the server\n",
        "            welcome_message = client_socket.recv(1024).decode('utf-8')\n",
        "            #print(\"Received welcome message:\", welcome_message)\n",
        "\n",
        "            # Loop until max words generated or a period token is found\n",
        "            for _ in range(max_words):\n",
        "                next_word = None\n",
        "\n",
        "                print(prompt_words)\n",
        "\n",
        "                # Keep asking the server until a valid next word is received\n",
        "                while not next_word:\n",
        "                    # Prepare the message to send with \"??\" appended\n",
        "                    message = \"classify \" + \" \".join(prompt_words) + \" ??\\n\"\n",
        "                    client_socket.sendall(message.encode('utf-8'))\n",
        "\n",
        "                    time.sleep(0.01)\n",
        "\n",
        "                    # Receive the server response\n",
        "                    data = client_socket.recv(1024).decode('utf-8')\n",
        "\n",
        "                    print(data)\n",
        "\n",
        "                    # Check for the CATEGORY line in the response\n",
        "                    lines = data.strip().splitlines()\n",
        "                    for line in lines:\n",
        "                        if line.startswith(\"CATEGORY \"):\n",
        "                            # Extract the word inside curly brackets\n",
        "                            match = re.search(r\"\\{(.*?)\\}\", line)\n",
        "                            if match:\n",
        "                                next_word = match.group(1)  # Extract the predicted word inside `{}`\n",
        "\n",
        "                # Add the predicted word to the generated text\n",
        "                generated_tokens.append(next_word)\n",
        "\n",
        "                print(generated_tokens)\n",
        "\n",
        "                # Shift prompt words and add the new word\n",
        "                prompt_words = prompt_words[1:] + [next_word]\n",
        "\n",
        "                # Stop if a period is generated\n",
        "                #if next_word == \".\":\n",
        "                #    break\n",
        "\n",
        "        # Detokenize the generated tokens\n",
        "        generated_text = tokenizer.convert_tokens_to_string(generated_tokens)\n",
        "\n",
        "        # Strip off original padding characters\n",
        "        generated_text = generated_text.replace(\"_\", \"\").strip()\n",
        "\n",
        "        # Print the final generated text\n",
        "        print(\"Generated text:\", generated_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Example usage\n",
        "#host = '135.181.158.92'  # Server's IP address or hostname\n",
        "host = 'localhost'  # Server's IP address or hostname\n",
        "port = 8888              # Port number on the server\n",
        "initial_prompt = input(\"Enter your initial prompt: \")\n",
        "\n",
        "generate_text_from_server(host, port, initial_prompt)"
      ],
      "metadata": {
        "id": "4lX5VkqCtenb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}