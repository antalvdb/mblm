{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDmztQBFGTLz+iihLHhCoM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antalvdb/mblm/blob/main/timbl_llm_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "9uhJeURORTUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import re\n",
        "import time\n",
        "import argparse\n",
        "import sys"
      ],
      "metadata": {
        "id": "W3ElZ4BNsdKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python3-timbl\n",
        "\n",
        "import timbl"
      ],
      "metadata": {
        "id": "SspA9rKassIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global verbosity level\n",
        "VERBOSITY = 1"
      ],
      "metadata": {
        "id": "_DDg3l-atTDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log(message, level=1):\n",
        "    \"\"\"Logs a message if the verbosity level is sufficient.\"\"\"\n",
        "    if VERBOSITY >= level:\n",
        "        print(message)"
      ],
      "metadata": {
        "id": "799oZv-Ruz_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_prompt(words, max_len=16):\n",
        "    \"\"\"Pad or trim the list of words to make it exactly `max_len` words.\"\"\"\n",
        "    if words is None:\n",
        "        words = []  # Ensure words is a list\n",
        "    if len(words) < max_len:\n",
        "        words = ['_'] * (max_len - len(words)) + words\n",
        "    else:\n",
        "        words = words[-max_len:]\n",
        "    return words"
      ],
      "metadata": {
        "id": "aorFqUootV-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h79ofJcqHDq"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import time\n",
        "import re\n",
        "\n",
        "def generate_text_from_server(host, port, initial_prompt, max_words=200):\n",
        "\n",
        "    # Tokenize the initial prompt and convert tokens back to words\n",
        "    initial_tokens = tokenizer.tokenize(initial_prompt)\n",
        "\n",
        "    if initial_tokens is None:\n",
        "        print(\"Tokenization failed; 'initial_tokens' is None.\")\n",
        "        initial_tokens = []\n",
        "\n",
        "\n",
        "    # Prepare the initial prompt, padded or trimmed to 8 words\n",
        "    prompt_words = pad_prompt(initial_tokens)\n",
        "\n",
        "    generated_tokens = prompt_words[:]  # Store the full generated text\n",
        "\n",
        "    # Print the initial prompt tokens\n",
        "    log(f\"Initial prompt tokens: {' '.join(initial_tokens)}\", level=3)\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Create a socket connection\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as client_socket:\n",
        "            # Connect to the server\n",
        "            client_socket.connect((host, port))\n",
        "\n",
        "            # Receive the initial \"Welcome\" message from the server\n",
        "            welcome_message = client_socket.recv(1024).decode('utf-8')\n",
        "            log(f\"Received welcome message: {welcome_message}\", level=3)\n",
        "\n",
        "            received_data = \"\"  # Buffer to accumulate received data\n",
        "\n",
        "            # Loop until max words generated\n",
        "            for _ in range(max_words):\n",
        "                next_word = None\n",
        "\n",
        "                log(f\"Current prompt: {' '.join(prompt_words)}\", level=3)\n",
        "\n",
        "                # Prepare the message to send with \"??\" appended\n",
        "                message = \"classify \" + \" \".join(prompt_words) + \" ??\\n\"\n",
        "                client_socket.sendall(message.encode('utf-8'))\n",
        "\n",
        "                # Loop to receive data until a complete category line is found\n",
        "                while next_word is None:\n",
        "                    data = client_socket.recv(1024).decode('utf-8')\n",
        "                    received_data += data\n",
        "                    log(f\"Received data (accumulated): {received_data}\", level=3)\n",
        "\n",
        "                    # Process complete lines from the buffer\n",
        "                    lines = received_data.splitlines()\n",
        "                    # Keep the last incomplete line in the buffer\n",
        "                    if received_data.endswith('\\n'):\n",
        "                        received_data = \"\"\n",
        "                    else:\n",
        "                        received_data = lines[-1]\n",
        "                        lines = lines[:-1]\n",
        "\n",
        "\n",
        "                    for line in lines:\n",
        "                        log(f\"Processing line: {line}\", level=3)\n",
        "                        if line.startswith(\"CATEGORY \"):\n",
        "                            # Extract the word inside curly brackets\n",
        "                            match = re.search(r\"\\{(.*?)\\}\", line)\n",
        "                            if match:\n",
        "                                next_word = match.group(1)  # Extract the predicted word inside `{}`\n",
        "                                log(f\"Extracted next word: {next_word}\", level=3)\n",
        "                                break  # Found the category line, break inner loop\n",
        "                    #if next_word is None:\n",
        "                    #    time.sleep(0.1) # Wait a bit before trying to receive more data\n",
        "\n",
        "                #time.sleep(0.15)\n",
        "\n",
        "                # Add the predicted word to the generated text only if it's not None\n",
        "                if next_word is not None:\n",
        "                  generated_tokens.append(next_word)\n",
        "                  # Print the generated token after converting it to a string\n",
        "                  print(tokenizer.convert_tokens_to_string([next_word]), end=\"\")\n",
        "\n",
        "                  log(f\"Predicted word: {next_word}\", level=3)\n",
        "\n",
        "                  # Shift prompt words and add the new word\n",
        "                  prompt_words = prompt_words[1:] + [next_word]\n",
        "                else:\n",
        "                  log(\"Could not extract next word from server response.\", level=2)\n",
        "                  # Optionally, handle the case where no word is predicted, e.g., stop or use a placeholder\n",
        "                  break # Stop generating if no word is predicted\n",
        "\n",
        "\n",
        "                # Stop if a period is generated\n",
        "                #if next_word == \".\":\n",
        "                #    break\n",
        "\n",
        "\n",
        "        # Detokenize the generated tokens\n",
        "        # generated_text = tokenizer.convert_tokens_to_string(generated_tokens)\n",
        "\n",
        "        # Strip off original padding characters\n",
        "        # generated_text = generated_text.replace(\"_\", \"\").strip()\n",
        "\n",
        "\n",
        "        # Print the final generated text\n",
        "        # log(f\"Generated text: {generated_text}\", level=1)\n",
        "\n",
        "    except Exception as e:\n",
        "        log(f\"Error: {e}\", level=1)\n",
        "\n",
        "    # Add a newline at the end for cleaner output\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Example usage\n",
        "host = '85.215.105.128'  # Server's IP address or hostname\n",
        "port = 8001              # Port number on the server\n",
        "initial_prompt = input(\"Enter your initial prompt: \")\n",
        "\n",
        "generate_text_from_server(host, port, initial_prompt)"
      ],
      "metadata": {
        "id": "4lX5VkqCtenb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}