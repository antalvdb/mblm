{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antalvdb/mblm/blob/main/timbl_llm_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MBLEM for autoregressive text generation\n",
        "\n",
        "##A sample notebook exploring beam search and temperature\n",
        "\n",
        "This notebook serves to test and exemplify the use of Memory-Based Language Modeling (MBLM) for autoregression, i.e. for the generation of text based on prompts.\n",
        "\n",
        "The notebook finds its origin in the notebook created for Chapter 5 of the Natural Language Processing With Transformers book by Tunstall, Von Werra and Wolf, which highlighted the use of beam search and temperature in selecting optimal outputs.\n",
        "\n",
        "MBLM is a CPU-based LLM, so Colab Runtime can be set to CPU."
      ],
      "metadata": {
        "id": "wliCeZkDm1p-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Firing up MBLM\n",
        "\n",
        "We begin with loading an `mblm` model and its associated tokenizer. This requires importing several packages and installing `python3-timbl`.\n",
        "\n"
      ],
      "metadata": {
        "id": "ydIh9K-7HRWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import re\n",
        "import time\n",
        "import argparse\n",
        "import sys\n",
        "import ast"
      ],
      "metadata": {
        "id": "Ysj3W2oshvZr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python3-timbl\n",
        "\n",
        "import timbl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFk8Lop0h2i6",
        "outputId": "83dc312a-a9d4-476c-aa13-6e66b3ee2a93"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python3-timbl in /usr/local/lib/python3.11/dist-packages (2025.1.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py-heat-magic\n",
        "%load_ext heat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdMNZCi3RNdq",
        "outputId": "b0541630-40a1-4167-e4f6-46c58b49b11c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py-heat-magic in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (1.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (3.10.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (7.34.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (1.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (2.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (1.13.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (1.3.7)\n",
            "Requirement already satisfied: py-heat in /usr/local/lib/python3.11/dist-packages (from py-heat-magic) (0.0.6)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->py-heat-magic) (4.9.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter->py-heat-magic) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter->py-heat-magic) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter->py-heat-magic) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter->py-heat-magic) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter->py-heat-magic) (7.7.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (from jupyter->py-heat-magic) (4.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->py-heat-magic) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->py-heat-magic) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->py-heat-magic) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->py-heat-magic) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->py-heat-magic) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->py-heat-magic) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->py-heat-magic) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->py-heat-magic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->py-heat-magic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->py-heat-magic) (2025.2)\n",
            "Requirement already satisfied: pprofile in /usr/local/lib/python3.11/dist-packages (from py-heat->py-heat-magic) (2.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->py-heat-magic) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->py-heat-magic) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->py-heat-magic) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->py-heat-magic) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->py-heat-magic) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->py-heat-magic) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->py-heat-magic) (7.4.9)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->py-heat-magic) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->py-heat-magic) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->py-heat-magic) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->py-heat-magic) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter->py-heat-magic) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter->py-heat-magic) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter->py-heat-magic) (3.0.13)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->py-heat-magic) (2.0.5)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->py-heat-magic) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->py-heat-magic) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->py-heat-magic) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->py-heat-magic) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->py-heat-magic) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->py-heat-magic) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->py-heat-magic) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->py-heat-magic) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->py-heat-magic) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->py-heat-magic) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->py-heat-magic) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->py-heat-magic) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->py-heat-magic) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->py-heat-magic) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->py-heat-magic) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->py-heat-magic) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->py-heat-magic) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->py-heat-magic) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->py-heat-magic) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->py-heat-magic) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->py-heat-magic) (1.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->py-heat-magic) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->py-heat-magic) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->py-heat-magic) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->py-heat-magic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->py-heat-magic) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->py-heat-magic) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->py-heat-magic) (0.14.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->py-heat-magic) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter->py-heat-magic) (4.3.7)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter->py-heat-magic) (21.2.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (2.32.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter->py-heat-magic) (2.21.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter->py-heat-magic) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter->py-heat-magic) (4.13.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->py-heat-magic) (1.3.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (0.24.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (6.0.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (0.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->py-heat-magic) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->py-heat-magic) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->py-heat-magic) (2.22)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (24.11.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->py-heat-magic) (2.9.0.20241206)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/antalvdb/mblm\n",
        "%cd mblm\n",
        "!git lfs pull -I chatbot-instruction-prompts_tok.l16r0.igtree.ibase\n",
        "# !git lfs pull -I chatbot-instruction-prompts-100k_tok.l16r0.ibase\n",
        "%cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyyB0tMzh6YD",
        "outputId": "b5c6ea23-8d88-470e-c2a2-ef8f435e4ece"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mblm' already exists and is not an empty directory.\n",
            "/content/mblm\n",
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global verbosity level\n",
        "VERBOSITY = 1"
      ],
      "metadata": {
        "id": "-95laCQBajMA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log(message, level=1):\n",
        "    \"\"\"Logs a message if the verbosity level is sufficient.\"\"\"\n",
        "    if VERBOSITY >= level:\n",
        "        print(message)"
      ],
      "metadata": {
        "id": "iIAaKHVQaiQn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_prompt(words, max_len=16):\n",
        "    \"\"\"Pad or trim the list of words to make it exactly `max_len` words.\"\"\"\n",
        "    if words is None:\n",
        "        words = []  # Ensure words is a list\n",
        "    if len(words) < max_len:\n",
        "        words = ['_'] * (max_len - len(words)) + words\n",
        "    else:\n",
        "        words = words[-max_len:]\n",
        "    return words"
      ],
      "metadata": {
        "id": "eDxDn9vpZKj2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timbl\n",
        "import torch\n",
        "from transformers import AutoConfig, AutoTokenizer, PreTrainedModel\n",
        "import transformers\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TimblHuggingFaceModel(PreTrainedModel):\n",
        "\n",
        "    # Define a function to replace values with actual floats\n",
        "    def float_converter(match):\n",
        "        return f\"{match.group(1)}: {float(match.group(2))}\"\n",
        "\n",
        "    def __init__(self, config, timbl_classifier, tokenizer):\n",
        "        super().__init__(config)\n",
        "        self.timbl_classifier = timbl_classifier\n",
        "        self.tokenizer = tokenizer  # Store tokenizer\n",
        "        # Create an empty tensor for probabilities\n",
        "        self.probabilities_tensor = torch.empty(0, device=device)\n",
        "\n",
        "    def forward(self, input_ids, **kwargs):\n",
        "\n",
        "        #print(\"inside forward\")\n",
        "\n",
        "        # Convert input_ids to Timbl format\n",
        "        timbl_input = self.convert_to_timbl_input(input_ids)\n",
        "        log(f\"Timbl input: {timbl_input}\",level=3)\n",
        "\n",
        "        # Get Timbl predictions\n",
        "        classlabel, distribution, distance = self.timbl_classifier.classify(timbl_input)\n",
        "        log(f\"Classlabel: {classlabel}\", level = 3)\n",
        "        log(f\"Distribution: {distribution}\", level = 3)\n",
        "        log(f\"Distance: {distance}\", level = 3)\n",
        "        # Convert Timbl output to Hugging Face format\n",
        "        logits = self.convert_to_huggingface_logits(distribution)\n",
        "        log(f\"Logits: {logits}\", level = 3)\n",
        "\n",
        "        # Return logits and other relevant outputs\n",
        "        return transformers.modeling_outputs.CausalLMOutputWithCrossAttentions(logits=logits)\n",
        "\n",
        "    def convert_to_timbl_input(self, input_ids):\n",
        "\n",
        "        #print(\"inside convert_to_timbl_input\")\n",
        "\n",
        "        \"\"\"Converts Hugging Face input_ids to Timbl input format.\"\"\"\n",
        "        # Decode input_ids to a string of tokens\n",
        "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids.squeeze(0))\n",
        "        log(f\"Tokens: {tokens}\", level = 3)\n",
        "\n",
        "        # Return the array of tokens directly\n",
        "        return tokens\n",
        "\n",
        "    def convert_to_huggingface_logits(self, distribution):\n",
        "\n",
        "        # Bypassing the typical HuggingFace device setting and passing\n",
        "        device = \"cpu\"\n",
        "\n",
        "        # Get vocabulary size from the tokenizer\n",
        "        vocab_size = self.tokenizer.vocab_size\n",
        "\n",
        "        # Initialize logits with a default value (e.g., -inf)\n",
        "        logits = torch.full((1, vocab_size), float('-inf'), device=device)\n",
        "\n",
        "        # Filter out tokens not in the Hugging Face vocabulary\n",
        "        hf_token_ids = [self.tokenizer.convert_tokens_to_ids(word) for word in distribution.keys()\n",
        "                        if word in self.tokenizer.vocab] # Filter for valid tokens in vocabulary\n",
        "\n",
        "        # Get probabilities only for valid tokens in\n",
        "        probabilities = [distribution[word] for word in distribution.keys()\n",
        "                          if word in self.tokenizer.vocab] #Filter for valid tokens in vocabulary\n",
        "\n",
        "        # Convert hf_token_ids to tensor only once, after filtering\n",
        "        if hf_token_ids:\n",
        "            hf_token_ids_tensor = torch.tensor(hf_token_ids, device=device)\n",
        "\n",
        "            # Resize the probabilities tensor after filtering\n",
        "            self.probabilities_tensor.resize_(len(probabilities)).copy_(torch.tensor(probabilities))\n",
        "\n",
        "            logits[0].scatter_(0, hf_token_ids_tensor, self.probabilities_tensor)  # In-place scatter\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def custom_generate(self, input_ids, max_new_tokens, num_beams=1, do_sample=False, temperature=1.0, top_k=0, **kwargs):\n",
        "        \"\"\"\n",
        "        Generates text using the Timbl model iteratively, with optional beam search and temperature.\n",
        "\n",
        "        Args:\n",
        "            input_ids: The input token IDs as a torch tensor.\n",
        "            max_new_tokens: The maximum number of tokens to generate.\n",
        "            num_beams: The number of beams for beam search (default is 1, which is greedy decoding).\n",
        "            do_sample: If True, use temperature sampling, otherwise use greedy decoding or beam search.\n",
        "            temperature: The temperature for sampling (default is 1.0).\n",
        "            top_k:  The number of top tokens to consider during sampling.\n",
        "            kwargs: Additional arguments (not currently used but kept for consistency).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The generated sequence of token IDs.\n",
        "        \"\"\"\n",
        "        batch_size = input_ids.shape[0]\n",
        "\n",
        "        # Initialize variables for beam search\n",
        "        if num_beams > 1 and not do_sample:\n",
        "\n",
        "            #Create a list to store the sequences\n",
        "            sequences = [input_ids.clone() for _ in range(num_beams)]\n",
        "\n",
        "            # Create a list to store scores for the sequences\n",
        "            sequence_scores = [torch.zeros(batch_size, device=input_ids.device) for _ in range(num_beams)]\n",
        "\n",
        "        else:\n",
        "            sequences = [input_ids.clone()]  # Start with the input ids\n",
        "\n",
        "        # Tokenize the initial prompt and convert tokens back to words\n",
        "        initial_tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "        # Generate padded instances\n",
        "        padded_instances = []\n",
        "        for i in range(len(initial_tokens)):\n",
        "            # Take the tokens up to the current position and pad them\n",
        "            instance = pad_prompt(initial_tokens[:i], max_len=16)\n",
        "            padded_instances.append((instance, initial_tokens[i] if i < len(initial_tokens) else '_'))\n",
        "\n",
        "        # Add instances to memory: note that this should be optional\n",
        "        for input_instance, next_token in padded_instances:\n",
        "            log(f\"memorized from prompt: {input_instance} {next_token}\", level=2)\n",
        "            self.timbl_classifier.append(input_instance, next_token)\n",
        "\n",
        "        with torch.no_grad():\n",
        "             for _ in range(max_new_tokens):\n",
        "\n",
        "                all_candidates = [] #Store all candidates in the beam search\n",
        "\n",
        "                for i, seq in enumerate(sequences):\n",
        "                    # Pad the input tokens\n",
        "                    tokens = self.tokenizer.convert_ids_to_tokens(seq[0])\n",
        "                    padded_tokens = pad_prompt(tokens, max_len=16)\n",
        "                    log(f\"padded_tokens: {padded_tokens}\", level = 3)\n",
        "\n",
        "                    # Convert padded_tokens back into token_ids for timbl input\n",
        "                    timbl_input_ids = self.tokenizer.convert_tokens_to_ids(padded_tokens)\n",
        "                    timbl_input_ids = torch.tensor(timbl_input_ids, dtype=torch.int64).unsqueeze(0).to(\"cpu\")\n",
        "\n",
        "                    # Get model output\n",
        "                    outputs = self(timbl_input_ids)\n",
        "                    logits = outputs.logits\n",
        "\n",
        "                    #Apply log softmax on the logits\n",
        "                    log_probs = F.log_softmax(logits[:, 1:], dim=-1)\n",
        "\n",
        "                    if do_sample: #if temperature sampling is enabled\n",
        "                      # Apply temperature scaling\n",
        "                      scaled_logits = logits[:, 1:] / temperature\n",
        "\n",
        "                      # Apply top-k filtering\n",
        "                      if top_k > 0:\n",
        "                            filter_value = -float('Inf')\n",
        "                            top_k_values, _ = torch.topk(scaled_logits, top_k, dim=-1)\n",
        "                            min_top_k = top_k_values[:, -1].unsqueeze(-1)  # Get the smallest top-k value\n",
        "                            scaled_logits = torch.where(scaled_logits < min_top_k, torch.tensor(filter_value).to(\"cpu\"), scaled_logits)\n",
        "\n",
        "                      # Sample from the distribution\n",
        "                      probabilities = torch.softmax(scaled_logits, dim=-1)\n",
        "                      predicted_token_id = torch.multinomial(probabilities, num_samples=1) + 1  # sample\n",
        "                      # Correct the unsqueeze dimension\n",
        "                      sequences[i] = torch.cat((seq, predicted_token_id.unsqueeze(0).squeeze(0)), dim=1)\n",
        "\n",
        "                    elif num_beams > 1: # If beam search is enabled\n",
        "                        top_k_probs, top_k_ids = torch.topk(log_probs, num_beams, dim=-1)\n",
        "\n",
        "                        #Prepare the candidate sequences\n",
        "                        for j in range(num_beams):\n",
        "                            candidate_seq = torch.cat((seq, top_k_ids[:,j].unsqueeze(0) + 1), dim=1)\n",
        "                            candidate_score = sequence_scores[i] + top_k_probs[:,j] #accumulate the score\n",
        "                            all_candidates.append((candidate_seq, candidate_score))\n",
        "                    else: #if greedy decoding is enabled\n",
        "                        predicted_token_id = torch.argmax(logits[:, 1:], dim=-1) + 1\n",
        "                        sequences[i] = torch.cat((seq, predicted_token_id.unsqueeze(0)), dim=1)\n",
        "\n",
        "                if num_beams > 1 and not do_sample:\n",
        "                    #Select the top num_beams candidates based on score\n",
        "                    ordered_candidates = sorted(all_candidates, key=lambda x: x[1], reverse=True)\n",
        "                    sequences = [seq for seq, _ in ordered_candidates[:num_beams]]\n",
        "                    sequence_scores = [score for _, score in ordered_candidates[:num_beams]]\n",
        "\n",
        "        return sequences[0]  # Return the generated sequence of token IDs\n",
        ""
      ],
      "metadata": {
        "id": "DxdP-1LQVmG1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "# Initialize the Timbl classifier\n",
        "classifier = timbl.TimblClassifier('/content/mblm/chatbot-instruction-prompts_tok.l16r0.igtree', '-a1 +D')\n",
        "classifier.load()\n",
        "\n",
        "config = AutoConfig.from_pretrained(\"antalvdb/mblm-chatbot-instruction-prompts-igtree\")\n",
        "tokenizer.add_special_tokens({'pad_token': '_'})\n",
        "tokenizer.pad_token = \"_\"\n",
        "\n",
        "# Initialize the TimblHuggingFaceModel\n",
        "model = TimblHuggingFaceModel(config, classifier, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbvExyBKixgd",
        "outputId": "253bb690-a207-4578-91e9-1e9bcac25f9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calling Timbl API : -F Tabbed -a1 +D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to feed the model with a prompt, *Why is the sky blue?*. We are running the model for eight steps; it will generate eight subsequent words. At each step, the model is capable of generating a token probability distribution over the entire vocabulary, but we are going to constrain this to just the top-5 most likely words per step, and the single most likely word is going to be fed into the input for the next step.\n",
        "\n",
        "The results are shown in a table. Read the table closely and check at each step whether you also consider the choices for next words sensible."
      ],
      "metadata": {
        "id": "HkLHSfkzH82R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "input_txt = \"Why is the sky blue?\"\n",
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
        "iterations = []\n",
        "n_steps = 8\n",
        "choices_per_step = 5\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(n_steps):\n",
        "\n",
        "        # Convert input_ids to tokens\n",
        "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "        # Pad the tokens\n",
        "        padded_tokens = pad_prompt(tokens, max_len=16)\n",
        "        iteration = dict()\n",
        "        iteration[\"Input\"] = padded_tokens\n",
        "\n",
        "        # Re-encode the padded tokens\n",
        "        encoded_input = tokenizer.encode(\" \".join(padded_tokens), return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=16, add_special_tokens=False)\n",
        "        input_ids = encoded_input[0].to(device)  # Access the first sequence\n",
        "\n",
        "        output = model(input_ids=input_ids)\n",
        "        logits = output.logits # extract logits\n",
        "\n",
        "        # Select logits of the first batch and the last token and apply softmax\n",
        "        # next_token_logits = output.logits[0, -1, :]\n",
        "        next_token_logits = output.logits[0, :]\n",
        "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
        "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
        "\n",
        "        # Store tokens with highest probabilities\n",
        "        for choice_idx in range(choices_per_step):\n",
        "            token_id = sorted_ids[choice_idx]\n",
        "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
        "            token_choice = (\n",
        "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
        "            )\n",
        "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
        "\n",
        "        # Append predicted next token to input\n",
        "        predicted_token_id = torch.argmax(logits[:, 1:], dim=-1) + 1\n",
        "        input_ids = torch.cat((input_ids[1:].unsqueeze(0), predicted_token_id.unsqueeze(0)), dim=1)\n",
        "        iterations.append(iteration)\n",
        "\n",
        "pd.DataFrame(iterations)"
      ],
      "metadata": {
        "id": "Jjw-vBv9pjZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "7922a47c-fc37-4a7d-d62c-f31cc117c4de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Input         Choice 1  \\\n",
              "0  [_, _, _, _, _, _, _, _, _, _, Why, is, the, s...     The (50.00%)   \n",
              "1  [_, _, _, _, _, _, _, _, _, Why, is, the, sky,...        I (0.53%)   \n",
              "2  [_, _, _, _, _, _, _, _, Why, is, the, sky, bl...        ' (6.09%)   \n",
              "3  [_, _, _, _, _, _, _, Why, is, the, sky, blue,...       m (67.13%)   \n",
              "4  [_, _, _, _, _, _, Why, is, the, sky, blue, ?,...  saying (16.67%)   \n",
              "5  [_, _, _, _, _, Why, is, the, sky, blue, ?, \",...   film (100.00%)   \n",
              "6  [_, _, _, _, Why, is, the, sky, blue, ?, \", I,...  major (100.00%)   \n",
              "7  [_, _, _, Why, is, the, sky, blue, ?, \", I, ',...      , (100.00%)   \n",
              "\n",
              "                Choice 2            Choice 3            Choice 4  \\\n",
              "0             \" (50.00%)     deepest (0.00%)  Volunteers (0.00%)   \n",
              "1              . (0.53%)         The (0.52%)           \" (0.51%)   \n",
              "2           said (5.75%)         can (5.43%)         don (5.43%)   \n",
              "3            ll (32.87%)     deepest (0.00%)  Volunteers (0.00%)   \n",
              "4             s (16.67%)      doing (16.67%)      happy (16.67%)   \n",
              "5        deepest (0.00%)  Volunteers (0.00%)         ##ń (0.00%)   \n",
              "6        deepest (0.00%)  Volunteers (0.00%)         ##ń (0.00%)   \n",
              "7  constellation (0.00%)         ##ń (0.00%)      troupe (0.00%)   \n",
              "\n",
              "             Choice 5  \n",
              "0         ##ń (0.00%)  \n",
              "1           , (0.51%)  \n",
              "2        like (5.28%)  \n",
              "3         ##ń (0.00%)  \n",
              "4         no (16.67%)  \n",
              "5      troupe (0.00%)  \n",
              "6      troupe (0.00%)  \n",
              "7  postseason (0.00%)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4461f3f9-53b2-40ad-8d18-98717807f39d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Choice 1</th>\n",
              "      <th>Choice 2</th>\n",
              "      <th>Choice 3</th>\n",
              "      <th>Choice 4</th>\n",
              "      <th>Choice 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[_, _, _, _, _, _, _, _, _, _, Why, is, the, s...</td>\n",
              "      <td>The (50.00%)</td>\n",
              "      <td>\" (50.00%)</td>\n",
              "      <td>deepest (0.00%)</td>\n",
              "      <td>Volunteers (0.00%)</td>\n",
              "      <td>##ń (0.00%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[_, _, _, _, _, _, _, _, _, Why, is, the, sky,...</td>\n",
              "      <td>I (0.53%)</td>\n",
              "      <td>. (0.53%)</td>\n",
              "      <td>The (0.52%)</td>\n",
              "      <td>\" (0.51%)</td>\n",
              "      <td>, (0.51%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[_, _, _, _, _, _, _, _, Why, is, the, sky, bl...</td>\n",
              "      <td>' (6.09%)</td>\n",
              "      <td>said (5.75%)</td>\n",
              "      <td>can (5.43%)</td>\n",
              "      <td>don (5.43%)</td>\n",
              "      <td>like (5.28%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[_, _, _, _, _, _, _, Why, is, the, sky, blue,...</td>\n",
              "      <td>m (67.13%)</td>\n",
              "      <td>ll (32.87%)</td>\n",
              "      <td>deepest (0.00%)</td>\n",
              "      <td>Volunteers (0.00%)</td>\n",
              "      <td>##ń (0.00%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[_, _, _, _, _, _, Why, is, the, sky, blue, ?,...</td>\n",
              "      <td>saying (16.67%)</td>\n",
              "      <td>s (16.67%)</td>\n",
              "      <td>doing (16.67%)</td>\n",
              "      <td>happy (16.67%)</td>\n",
              "      <td>no (16.67%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[_, _, _, _, _, Why, is, the, sky, blue, ?, \",...</td>\n",
              "      <td>film (100.00%)</td>\n",
              "      <td>deepest (0.00%)</td>\n",
              "      <td>Volunteers (0.00%)</td>\n",
              "      <td>##ń (0.00%)</td>\n",
              "      <td>troupe (0.00%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[_, _, _, _, Why, is, the, sky, blue, ?, \", I,...</td>\n",
              "      <td>major (100.00%)</td>\n",
              "      <td>deepest (0.00%)</td>\n",
              "      <td>Volunteers (0.00%)</td>\n",
              "      <td>##ń (0.00%)</td>\n",
              "      <td>troupe (0.00%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[_, _, _, Why, is, the, sky, blue, ?, \", I, ',...</td>\n",
              "      <td>, (100.00%)</td>\n",
              "      <td>constellation (0.00%)</td>\n",
              "      <td>##ń (0.00%)</td>\n",
              "      <td>troupe (0.00%)</td>\n",
              "      <td>postseason (0.00%)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4461f3f9-53b2-40ad-8d18-98717807f39d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4461f3f9-53b2-40ad-8d18-98717807f39d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4461f3f9-53b2-40ad-8d18-98717807f39d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c61c2be-59d3-4d71-8848-085e948c64b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c61c2be-59d3-4d71-8848-085e948c64b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c61c2be-59d3-4d71-8848-085e948c64b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"I (0.53%)\",\n          \"film (100.00%)\",\n          \"The (50.00%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\\\" (50.00%)\",\n          \". (0.53%)\",\n          \"deepest (0.00%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"deepest (0.00%)\",\n          \"The (0.52%)\",\n          \"##\\u0144 (0.00%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 4\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Volunteers (0.00%)\",\n          \"\\\" (0.51%)\",\n          \"troupe (0.00%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"##\\u0144 (0.00%)\",\n          \", (0.51%)\",\n          \"postseason (0.00%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A shorthand for generating the output above is the following code:"
      ],
      "metadata": {
        "id": "JUC3sDqhJUQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer(input_txt, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "output = model.custom_generate(**tokenized, max_new_tokens=n_steps, do_sample=False)\n",
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "id": "SZe6ytHjpoFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621f2e2f-af2b-4818-8514-596a3306a6a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why is the sky blue? \" I ' m a film major,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now prompting the model with a larger input text, and asking it to generate a text no longer than 128 words. Notice the interesting repetitive behavior in the output, which is an undesirable property. In fact, always choosing the top-most likely word at every next step, the so-called **greedy** strategy, is not a good strategy in text generation. There are several improvement strategies."
      ],
      "metadata": {
        "id": "NWstOEMmJyL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "input_txt = \"The wave of new import taxes is expected to cost American consumers and businesses hundreds of billions of dollars, radically altering the economic outlook.\"\n",
        "#input_txt = \"Transformers are the best\"\n",
        "tokenized = tokenizer(input_txt, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "output_greedy = model.custom_generate(**tokenized, max_new_tokens=max_length, do_sample=False)\n",
        "print(tokenizer.decode(output_greedy[0]))"
      ],
      "metadata": {
        "id": "xub3jBc759Cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f41d14-e31a-44e9-9d0b-d500ba045de6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The wave of new import taxes is expected to cost American consumers and businesses hundreds of billions of dollars, radically altering the economic outlook. Businesses are being affected as countries around the world impose restrictions on movement, reducing economic activity. Unemployment is on the rise, and spending continues to decrease in both individuals and businesses. This has caused a global recession, with some countries faring worse than others. In addition, many countries have put stimulus packages in place to help mitigate the effects of the pandemic, but the end result is still uncertain, the region overall is expected to experience a strong recovery in the coming year. 1. Plant - based eating : Plant - based eating is becoming more popular every year and will continue to trend in 2021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One better strategy than the greedy strategy is to perform beam search over multiple sequences of tokens.\n",
        "\n",
        "![chapter05_beam-search.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABTEAAAKCCAYAAAAJCp2sAAAACXBIWXMAAC4jAAAuIwF4pT92AAAgAElEQVR42uzdf3xU9Z3v8ffc22trhwoudjO4KBAqzWDvZPhRaxLEWJFEypZAGm6p9RJXlhS2VrC94EWNiD+u2BVw7aJhg4J2S2+mCK4UErRXfoVYqjKZrSSLZQRl3UwrK1Smbu1jH3P/yOQwJzNJJslk5syc1/Px4PGYkzkzc/jMfOfMvOf7wxGJRAQAAABYTSDgHytpmaQKSWOoCLLYOUn7JG3weLz7crStrpZUSltFDrTVnZK25GJbBbKdgxATAAAAVhMI+JepMxQZTjWQY/ZLqvB4vGdzpK1ukHQnTyty0BOSVudKWwVyASEmAAAALCUQ8G+RtJBKIIedk1Tq8Xj9WdxOR6izd2khTydyWGu0rRJkAhbwXygBAAAArCIQ8K8WASZy33BJW6JBYLbaIAJM5L5CdQ4vB2ABhJgAAACwhOi8evdTCdhEoTrnfM3GtloqfmyAfVwfCPirKQOQeYSYAAAAsIrVlAA2syxLe2PSVsH5CUDaEWICAADAKkopAWxmeLa97qOh6/U8dbCZMYGA30sZgMwixAQAAEDGRYORMVQCNuTleAFe+wD6RogJAAAAvhwCANC7sZQAyCxCTAAAAAAAAACWRogJAAAAAAAAwNIIMQEAAAAAAABYGiEmAAAAAAAAAEsjxAQAAAAAAABgaYSYAAAAAAAAACyNEBMAAAAAAACApRFiAgAAAAAAALC0T1ECAAAAAADQH4WFk4zL5eVlWrv2UYoCYEjRExMAAAAAAACApdETEwAAAEBaBINBnT9/3tj2eDwUBQAAJIUQEwAAAEBa1NVtUmNjk7Hd2nqUogAAgKQwnBwAAAAAAACApRFiAgAAAAAAALA0QkwAAAAAAAAAlsacmAAAAIBFBAIB7d9/QM3Nh9XW1tbrvrW196mycp4kqbBwUtzfm5r2aseOnWppaVF5eZnWrn3UdPtQKKQ9exrV2NhkPJbLlafZs2fr+uun97joTjgc1qFDzXr99df13nun1dLSYlzndrtVUlIcd/uVK+82zYXZJdFxA6nU39d5OBzWvHmV6ugIGX/bu7dReXl5cW311lsXGtuPPbZWZWUzB9xGemsTgUBAL720SwcOHFBHR8g4/r/6q9vkdDolSU1Ne/X666+rocFn+j/G7tPb45SXl6mxsUkvv/yKcbxut1tVVd9QeXlZwvsYivoDQG8IMQEAAAALePLJH6m+fnNa7qupaa/WrVtnCmokqaMjpPr6zaqv36zly5epunph3G0bG5u0Zs2DCe+3ra1NbW1tqq/fbAp1gEwYyOvc6XRq8eLFptd4Q4NPd9zxXdN9vPTSLuOy2+02vdZT1Ubef//9hD8AdB3/W28d09Kl39HGjU+bgtLYfZqbD2vz5n/oNYRsb283hZexx7pmzYN6+eVX9PjjP+x3kDmY9xkASITh5AAAAECGbd/+gil0LCoqUm3tfVq06Ha5XOYeYIsW3a7a2vt01VVfSHhfmzZt6jXADAQCWrFiZVyw0N369Rt0+PDhAf+fVqxYqVAoxJOLjBjM67y8vMzU7urrN5tey6FQyOjxKEm33VY9JG2kvn5zwh7MXVpaWnTrrQvjwsdYbW1tvd6H1BnS9nYfLS0tPYaymX6fAWAv9MQEAAAAMigcDmvTpk3G9qJFt5t6fX3ta7M0d26l6Ta9DbvuCg2Kiop0000zJEnDhg0zrt+48WnjssuVp/vvr1VxcbEk6fDhw1qy5G+M6//u735kXNflqqu+oOef3xo3DDQQCMT1CDt0qFmVlfO0du2jWrv20bheZa2tR3kBYEgM5nXeV2/M2ACzey/MgbaRnpSXl+mrX/2qRo1ySersARr7+Mns097e3me9Fi26XVOmTDbeK/bvP2D6MaSxsUk1NYuVn58/5PUHgJ7QExMAAADIoNbWVlNvpfnzq0zX5+fnm/7W3Nx7ryW3260dO7br6ac3qrJynior5xkhSzAYNAUoixcvNoUHxcXFWr58mbHd1tamYDBoun+Px5NwHjuPx6MVK35g+tuRI0d4gpF2qXidl5eXye12G9u7du1SOBxWOBw2hXuJemGmqo10zWVbVjbTuM9ly+7s9z6///3ve61XeXmZ7rjjuyouLjbu4447vqva2vtM+x096k9b/QEgEXpiAgAAABn0b//WYdruvoCIJBUUFJi+8PdmzJgre+wt1T2EmDatJG6fyZMnxd0m2d5Xye6HC3bt+nl1YeGk0mw53oqKihEPPHC/pY8xFa9zp9Op226r1ooVKyV19nDuPiw7US/MoW4jycxLOdBFeLrrXrcjR44ktfjWUL/PALAvQkwAAADAJmJ7fbnd7oSBafceZB999BGFG0IfffTRGEljsuV4w+Hztnmdl5XN1LPPbjF+ONi0aZMuvfTPjOsHOhdmtsjLy5Pb7Tb+/6dOvcv7DICMYjg5AAAAYCHhcLjX67sv9NMffv+FHlJjxlyZ1G366vnZJRgMKhAI8AQi41L5Oo8NKjs6QsZ+A+mFmY1tJLZ+yb4XDOX7DAB7oycmAAAAkEHdVxk/dKg5Lhx5+eVXjMvTp08f8GPFzr3p9/u1cuXdA76vpqa9On78uN5661ivKxujdwsWfPOB//N/Hl2dLccbCPhLJb1q5WNM5eu8e2/MLlVV36CNpKH+ABCLEBMAAADIII/HYxqyuW7dOo0a5ZLH41E4HNYzzzxrCkBuuKE0JY+baI6/ZASDQa1adS89p5AVBvo6j1VeXhb3eu/+4wNtZOjqDwBdCDEBAACADPve976rJUv+xvjSf+utCxPut2jR7aZVftMtFAppyZKlcaupFxQUaNiwYRo1ytXjsQPZKBQKadu2bXF//8d//EnCFchpIwAwdAgxAQAAgAwrLi7WokW3q75+c8LrXa48LViwQNXVqQs/ysvLtHbto/26TUODzxTOPPXU32c0VAWG4nXe22u+S2Njk2655VtxQWYut5GBzMc72PoDQCxCTAAAACDDmpr2GgFmbe19putGjXKpsLBQTqdz0I9TVFRkDE1PdqXhWM3Nh033RYAJKxrs67xLKBQy/bBQW3uf1qx50NhO1Bsz19pI7CI9Xq83rfUHgO5YnRwAAADIsHXr1hmXKyvnmf4VFxenJMCUpKuvnmhcbmtrUygU6tftY+f4Gz78Ep44WNJgX+ddGhp8xmW3263KynmaP7/K+FtjY1PcauO51EZCoZCpV6nb7U5r/QGgO0JMAAAAIIMCgYApKNi+/QUFAoG4f6kIAqZMmWza7mn4ejLoYQWrSsXrvHsvzNtuq5Yk/eVfzjbt94//+JOcbSOxIa4kTZhwVdrfZwAgFiEmAAAAkEHjx483ba9Z86BuvXVh3L+ZM8v1zW9+S9u3vzDgxyouLjb1pmpo8Onhhx9RMBg07RcKhdTUtFcrV95t6mlWVFRkXG5ra1NT017T7br3SuvukkvMPdNibx8Oh3kxICUG+zrvuk0Xt9utsrKZkiSPx6Py8jLjuu69MQfbRjLh1Kl3dfjwYVNb3L79BVP46Ha7kx4an4r6A0AizIkJAAAAZJDT6Yyba68nbW1tWrPmQX300UcDXuRn1aq7TasjNzT44npcxbrllm8Zl+fOrTDmupOkFStWaseOnRo+/BKdO/d703WJFBQUmLZXrFipFStWSmIBEKTWYF7ngUDAFOBVVX0jbt/GxiZjO3ZuzMG2kUxoa2vTkiV/0+s+3/ved9NWfwDoCT0xAQAAgAwrLy8zzbXXl/XrNwx4eLnH49Hzz29NaqVht9utvLwL+5WVzTT1QpOklpYWNTY2qaWlRS5XXtz13f+fA1nhGEjn6zx2iHii13RvvTEH20as6LHH1vZ7gaLB1B8AekJPTAAAACCDgsGglixZqo6OkFyuPD311Ebl5+eb9umany+2J5Pf32oMce0vj8ejF17YrsbGJh05csTUq8ztduu///cvaerUqQnvf+3aR3XNNdfo5ZdfMXqVud1ulZeXqarqG2psbDLdXyyn06nnntuqhgafdu3aZcwFWl5epjlzvs6LASk1kNd5IBAw7bd48eKEC2vNmfP1HntjDqaNZEJRUZFuumlG3PGWlBTra1+bFfd+lI73GQBIxBGJRKgCAAAAMioQ8JdKetVu/+9wOKx58yqNMO/557caQUiifYuLpxnbtbX3qbJyHi+e7PeAx+NdTVtFOhUWTjIuM5VDbrZVIBcxnBwAAADIkEOHmk0rk/cUYEpK2BsMAADALggxAQAAgAw5f/68abu3eS67r9571VVfoIAAAMA2CDEBAACADBk2bJhpu75+s8LhcNx+wWBQGzc+bWy73e5ee20CAADkGhb2AQAAADJk2rQSud1utbW1SZIaGnxqaPCZVi8+depd4/ou3/vedykeAACwFUJMAAAAIEOcTqceeeQhrVp1rymo7GnlYpcrT/ffX6vi4mKKBwAAbIUQEwAAAMig/Px8/fSnP1FT0169/vrreu+902ppaTGud7nyNH36dBUUFKi8vIwFfgAAgC0RYgIAAAAWUFY2U2VlMykEgCHX2nqUIgDIOizsAwAAAAAAAMDSCDEBAAAAAAAAWBohJgAAAKzgLCUAAHCeAtATQkwAAABknMfj9VMF2NRZjhfICpyngAwjxAQAAIBVvEgJYEM7s+lgoz84nOJpg82c83i8+ygDkFmEmAAAALCKDZQANrPf4/GezMLj3sJTB85PANKNEBMAAACW4PF497377nshKgEbWZalx71B9MaEfZwTISZgCYSYAAAAsASHw7Hl9tsX5f3ud7+jGLCD27J1LliPx3tWUoU6wx0g15VGX/MAMowQEwAAABnncDi2SFr429/+Vt/61rf10UcfvUdVkKPOqTPA3JLN/4loAFsqemQit9vqDSw8B1gHISYAAAAyqivA7Nr+7W9/e1tJyXVXSnpABCTILVslebM9wOwSDXe80bZKr0zkinPRtjqWxXwAi31mjEQiVAEAAACZ+TDaLcCUdFskEtkSu08g4C9VZ1AygoohS/kl7cv1IanRtlrK040stk+Sn+HjgEU/NxJiAgAAICMfRJMIMAEAAACJ4eQAAADIAAJMAAAA9AchJgAAANKKABMAAAD9RYgJAACAtCHABAAAwEAQYgIAACAtCDABAAAwUISYAAAAGHIEmAAAABgMQkwAAAAMKQJMAAAADBYhJgAAAIYMASYAAABSgRATAAAAQyJBgLmVABMAAAADQYgJAACAlOshwKymMgAAABgIQkwAAACklMPhqBYBJgAAAFKIEBMAAAApEw0wn435EwEmAAAABo0QEwAAAClBgAkAAIChQogJAACAQSPABAAAwFAixAQAAMCgEGACAABgqBFiAgAAYMAIMAEAAJAOhJgAAAAYEAJMAAAApAshJgAAAPqNABMAAADpRIgJAACAfiHABAAAQLoRYgIAACBpBJgAAADIBEJMAAAAJIUAEwAAAJlCiAkAAIA+EWACAAAgkwgxAQAA0CsCTAAAAGQaISYAAAB6RIAJAAAAKyDEBAAAQEIEmAAAALAKQkwAAADEIcAEAACAlRBiAgAAwIQAEwAAAFZDiAkAAAADASYAAACsiBATAAAAkggwAQAAYF2EmAAAACDABAAAgKURYgIAANgcASYAAACsjhATAADAxggwAQAAkA0IMQEAAGyKABMAAADZghATAADAhggwAQAAkE0+RQkAAOhdIOAvpQrIYic9Hu/J2D9kW4AZCPhHSPLyVCKX2iEA9FeNr53zIbL+fFhXVTDg86EjEolQQgAAuokGl8skzaEayAGnJG2RtKGwcFKFzAHmi5FIpIJ2CKSvHXo83rOUA0CyanztnA+Rk+fDuqqCfp0PCTEBAIgR7fG1QdJCqoFc8/HHH5/53veWjTxy5EjXn1ollUYikbO0QyCtX94qPB6vn1IA6E205+UWEV4ih8+HdVUFSZ8PCTEBAIgRCPj9kgqpBHLVH/7wB91553IdOXLEygHmPtohctw5SaUEmQB6Eg0wOR/CFufDZINMFvYBACAqEPBv4IMict1nP/tZPfnkE/9ZX7/pf1otwIxaTTuEDQyXtC8a2gNAIls4H8Iu58NoaN8nQkwAACQFAv6xku6kErCDz3zmM//1y1/+8l0WbIeltEPY7IvbBsoAoLvoHJgMIQfnw24IMQEA6LSaEsBmFkbDeyup5mmBDdshvTEBdLeMEsBu58NkemMSYgIA0KmCEsCGSmmHAK97AJZDL0zwuTQBQkwAgO1Fe8EMpxKwobEWaodjaYegHQKwuxpfu5cqwKb6fO0TYgIAkMQJE+C1P+TG8nQAACCmmAB6QIgJAADAFyUAAADA0ggxAQAAAAAAAFgaISYAAAAAAAAASyPEBAAAAAAAAGBphJgAAAAAAAAALI0QEwAAAAAAAIClEWICAAAAAAAAsDRCTAAAAAAAAACW9ilKAAAAAGS/wsJJxuXy8jKtXfsoRQEAADmDnpgAAAAAAAAALI2emAAAAAD6FAwGdf78eWPb4/FQFABAxn14+oQ++cNHxnbeBC9FyVGEmAAAAAD6VFe3SY2NTcZ2a+tRigIAyLg3t2/UiebdxvbihjaKkqMYTg4AAAAAAADA0ggxAQAAAAAAAFgaISYAAAAAAAAAS2NOTAAAkDbhcFiHDjXr9ddf13vvnVZLS4txndvtVklJsa6/fjoLhgBD2AYbG5t05MgR0/yW5eVluuaaa1RZOS/uNitX3m3at0th4STjcm3tfQlvCwDAUPnFE983zYXZZdN8t3H5usVr5J5RFbfPJx+f14nmPXr/rddM9zG+ZJYuv/rauNvsfmiRTgeaje1bnton58i8hMcVu+9oT4lm3VvPk5UihJgAACBtGhubtGbNgwmva2trU1tbm+rrN+uxx9aqrGwmBQNSKBgMatWqe9XW1pawbTY2Nsnn+5keeeQh5efnUzAAQE768PQJvfrkCn3wzrG4604079aJ5t1qe/mnuuGOx3Tp6PGSpHHXlplCzHePHugxHI3d7y88RRQ8hRhODgAALGfFipUKhUIUAkiRUCikJUuWJgwwY7W1tWnJkqUKh8MUDQCQc8JnQtr98KKEAWasD945pt0PL9InH5+XJLkKJpuuP3My8fn0t8f9pm1XwRSKnkKEmAAAIG2uuuoLev75rWptPWr69/zzW1VUZP6l+tChZgoGpMi6devV0XHhh4Ha2vt0+PAhtbYe1d69jZo//0Jvko6OkJ555llje+3aR9XaelTl5WWm+4xtwwwlBwCk2413Pq7FDW0aXzLL9PfFDW3Gv+69JV/78WMKn+kwtq9bvEbVW3+lxQ1tuuWpfZo4c4FxXfhMh1p3dg4Fv3T0eF02bqJx3bG92xIe078de9247BzpUt4EL09UChFiAgCAtPF4PAnnu/R4PFqx4gemvx05coSCASkQDAZNc1ouWnS7Kivnyel0SpLy8vJ0zz2rTD8k1NdvpjcmACCnfHj6hGn+y0lza+SeUaWLLh4mSXKOzNO0RbUa7Skx9jm6o87ojdk9LD3deijuMd7zHzQuT5g+h6KnGHNiArAth8OxjypAkioqKkY88MD9FCLDmIMv/c6cOeOyynsh7XDoHDhw0LQd2+sy1ty5FabFtg4damZuWgBAznj3TfNHnthel7EKbqw0zWt52n9Q+UU368rJpfrlj//2wueoU/+i0YXTjO3wmZBpmPrIsV+k6ClGiAnAzq6nBJCkcPg8RYAt/elPf/qMVd4LaYdDJ3YeTJcrT3l5iVdTveqqL5i2z5/nOQEA5I7YgNE50tXj6uKXXjHBtP3H6GeUS0ePl3OkyxiOfqJ5twq/fruxX+j4m6bbjfZeR9FTjOHkAAAg44LBoAKBAIUAhoDff2GRAa+357m5uveGZkoHAEAu6Wi/EDJ2X6gnVteK5F3ef+s143LsEPEP3jmm8JkL802fOfkvxuXRnhJjmDpSh56YACDtj0QipZTBvgIBf6mkV6lE+jQ17dXx48f11lvHTMNXkV4ul+tkJBIZSzvM8S9tMQv6AABgV7EL+gzUqIlTdXRHnbH97tEDxuJBsfNhjru2jIIPAUJMAACQNsFgUKtW3Wsa3goAAABkg9GF00xDys+c7PxM++HpE6bh6r319MTAEWICAIC0CIVCWrJkqalX2Pz5VSooKNCwYcM0apRLt966kEIBAADAssZMuUHH9m6TJB3bu03TFtWahqpfNm5i3JB0pAYhJgAASIuGBp8pwHzqqb9XcXExhQEs6pJLLqEIAADb+7RzuGn78qu/bISYkhQ67jd6ZErSFSzoM2RY2AcAAKRFc/Nh43JRUREBJpAm5eUX5uWKXeSnu2AwaNouKCigeACAnDG+ZJZxObbnZHcfnj5h2h451m3a7r7q+L+/+7ZOvXFhWu9RE6dS7CFCiAkAANIidh7M4cPp4QWky+jRoy98aesIKRRKvNDP22//xrQ9apSL4gEAcsYlf36FcTl8psO0snisD987btr+3OdHmbYvuniYJs5ccOEz7ss/NS0a9OcTvBR7iBBiAgCAtDt16l2KAKTJlCnmxQUaGnwJ93v22S3GZZcrj97SAICc0r2HZOyQ8Fj+nfXGZedIl0YXTovb5/Krv2xcjl3QZ+LMBbro4mEUe4gQYgIAgLQoKioyLre1tampaa/p+kAgQJGAIVBcXCy3+8JQuPr6zdq+/QWFw2FJnYtuPfzwI6be0osXL467n+5zZMa24a77AgAg3brPWRls2WNc/uTj88bl0YXTdNm4icb20R11anvFZ+wTPhPSofo1plBycuXShI+ZNyHx6uPdh54jtVjYBwAApMXcuRVqaWkxtlesWKkdO3Zq+PBLdO7c703XAUitVavu1q23LjS216x5UGvWPJhw36KiIlVWzov7e/c5MlesWKkVK1ZK6px3c+3aRyk0ACDtugeHr6y/S1p/l6TOeTBvvPNx47qS2+/Ti/deGAp+cFOtDm6qTXi/oz0lcs+oSnidc2SeRntKdDrQbPr7lZOm84QMIXpiAgCAtCgrm2laYESSWlpa1NjYpJaWFrlceXHXA0gNj8ejxx5bK5crr9f9ysvL9PjjP+zxur5uDwBAuo0vuVnOkcnN45w3wasZy9f1uf/4klma8f0Nve4z7lrz59bLxk2UcyTnyaFET0wAAJA2a9c+qmuuuUYvv/yK0fPS7XarvLxMVVXfUGNjkxobmygUMATKymZq2rQS+Xw/02uv/dJogy5XnqZPn66pU6eqrGxmj7d3Op167rmtamjwadeuXero6FwQoby8THPmfJ0CAwAy4qKLh6nioZ/q2N5tOn7gRWORnfEls/TF0rlx++cX3azR3uvU9vL/1b8GWozelM6RLo2ZcoMuv/rLyi+6uc/H7d7rMnb1cwwNRyQSoQoA7PkG6HB0vQHuj0QipVTEvgIBf6mkV6kEbGi/x+MtpR0CGfWAx+NdTRkASFKNr53zYZYIHfebhqbPuucfEi4ChOTPh3VVBb2eDxlODgAAAAAAAPRDR/sbxuWeVjFHahFiAgAAAAAAAEn65OPz+vWeHxvbE6bPoShpQIgJAAAAAAAAJOGTj8+rdWe9MfemJI2aOJXCpAEL+wAAAAAAAAC92DTfnfDv40tmMZQ8TeiJCQAAAAAAAPSTc6RLkyuXUog0IcQEAAAAAAAAejFx5oWVyJ0jXZo0t0YVD/1Ul44eT3HShOHkAAAAAAAAQC+mLarVtEW1FCKD6IkJAAAAAAAAwNIIMQEAAOzrLCUAAABANiDEBABA8lMC8NrPuJM8HQAA8AMj0BNCTACA7Xk83rOSzlEJ2NBJC7XDk7RD0A4BgPcE2FafP64TYgIA0GknJYAN7aMdArzuAfCeAGTD51JCTAAAOm2hBLCZrdHej7RDILPtkKGjACRJNb721ZKupxKw4/mwrqqgz/MhISYAAJI8Hu8+SU9QCdjEOUmraYdAxtvhMsoAQJJqfO2lku6nEuB82DNCTAAAojwe7zJJrVQCNlBhwV6YXVbTDmGTL2yl9MIEIEk1vvaxYhg5bHw+TKYXpkSICQBAd6WStlIG5KhTkiZFezxaUjTUoR0i19thqcfj9VMKAFE7JQ2nDLDj+bCuqiDp86EjEolQNgC25HA4ut4A90cikVIqgliBgL9UncMa5lAN5MiHxC2SNmRTzy/aIWiHAHJdja99g6Q7k9j1PyR9hoohl86HyfbANL7DE2ICsCtCTCQjEPCPkOSlEshiZ7O9xxftEDngpIWncACQITW+9mpJzya5+yRJJzkfItvPh3VVBQM+HxJiArAtQkwAAAAAmVDja/dK2qfkhpEvr6sq2EDVYHfMiQkAAAAAAJAmNb72EeocTptMgLmVABPoRIgJAAAAAACQPhskFSaxX6s654YGIEJMAAAAAACAtIjOg7kwiV3PSaru78InQC4jxAQAAAAAABhi0Xkwk13IZ1ldVYGfqgEXEGICAAAAAAAMoeg8mDuT3P2JuqqCLVQNMCPEBAAAAAAAGFpbJI1JYr/WuqoC5sEEEiDEBAAAAAAAGCI1vvZlkuYkses5SRVUDEiMEBMAAAAAAGAI1PjaSyWtT3L36rqqgpNUDUiMEBMAAAAAACDF+jkP5gN1VQU7qRrQM0JMAAAAAACA1NspaXgS++2vqypYTbmA3hFiAgAAAAAApFCNr321pOuT2JV5MIEkEWICAAAAAACkSI2vvULS/UnuXlFXVXCWqgF9I8QEAAAAAABIgRpf+1hJW5LcfXldVcE+qgYkhxATAAAAAAAgNZKdB/PFuqqCDZQLSB4hJgAAAAAAwCDV+No3SCpMYtdTkqqpGNA/hJgAAAAAAACDUONrr5Z0Z5K7Mw8mMACEmAAAAAAAAANU42v3Skp2aPhtdVUFfqoG9B8hJgAAAAAAwADU+NpHqHMhn2TmwdxaV1WwhaoBA0OICQAAAAAAMDDJzoPZKmkZ5QIGjhATAAAAAACgn2p87cskLS8J0LYAACAASURBVExi13OSqpkHExgcQkwAAAAAAIB+iM6DuT7J3ZcxDyYweISYAAAAAAAASYrOg7kzyd2fYB5MIDUIMQEAAAAAAJK3RdKYJPZrrasqYB5MIEUIMQEAAAAAAJJQ42tfLWlOEruek1RBxYDUIcQEAAAAAADoQ42vvVTS/UnuXlFXVXCSqgGpQ4gJAAAAAADQi37Og/lAXVXBPqoGpBYhJgAAAAAAQO92ShqexH7766oKVlMuIPUIMQEAAAAAAHpQ42vfIOn6JHZlHkxgCBFiAgAAAAAAJFDja6+QdGeSu5fWVRWcpWrA0CDEBAAAAAAA6KbG1z5W0pYkd19eV1Xgp2rA0CHEBAAAAAAAiJfsPJgv1lUVbKBcwNAixAQAAAAAAIhR42vfIqkwiV1PSaqmYsDQI8QEAAAAAACIqvG1V0tamMSu5yRVMA8mkB6fogQAAPT6IdYrqVTSCKqBLOWXtC+bv2DRDkE7zJq2Whptq0C22ifpPyUlOzR8WTrnwQwE/KWSvJwPke3nQ4/HO6DzoSMSiVBCALbkcDi63gD3RyIRPnCj+xexZZKWSRpDNZAjtkpaXVdVcDKL2uFqdQ7Rox2Cdmjddjoier5cpuTmDgSs7j8l/ddk2nNdVUF1Og4oEPCvpo0hF8+HHo+3X+dDQkwAtkWIiV6+jO1TcnMgAdnotrqqgi20QyBjzqmz99aWbP+PRHtJ7xQ/NMB+WiWVDnXv6kDAPzbaxjgfImfPhx6PN+nzIXNiAgBw4csYwQns4NnoXF+0QyAzhlu9HSbZVr3RtkqACbs5J6k6DQHmCHUOveV8iJw+HwYC/qTPh4SYAABcwC/dsItnowEE7RCgHfZb9MeGnWJoK+ypOk3zYNLGYBcbor2O+0SICQCAjMUIrqcSsNMHRtohQDscIOaMhl09UVdVsHOoHyTaM43zIexiuKTVyexIiAkAwIUvZICdXF/jax9LOwRohwNQzVMHG2qtqypYRhsDhsTCZHpjEmICANBpDiWADVXQDgHaYX9Eh8DTCxN29GgaH4temLCj0r52IMQEANhelvaCAVJhhIXaoZenA7RDjhewMFc6HiQQ8JdSathUn9/JCDEBAEjihAnkKCsFhwQjAAAr4zwFZBghJgAAAF/IAAAAAEsjxAQAAAAAAABgaYSYAAAAAAAAACyNEBMAAAAAAACApRFiAgAAAAAAALA0QkwAAAAAAAAAlkaICQAAAAAAAMDSCDEBAAAAAAAAWNqnKAEAABgqm+a7jcvjS2bpxjsfpygAAHCOBoB+oycmAAAAAAAAAEujJyYAAOi3D0+f0Cd/+MjYzpvgpSgAeM8AAAyJYDCo8+fPG9sej4ei2BAhJgAA6Lc3t2/UiebdxvbihjaKAoD3DADAkKir26TGxiZju7X1KEWxIYaTAwAAAAAAALA0QkwAAAAAAAAAlkaICQAAAAAAAMDSmBMTAAAk7RdPfN80r12XTfPdxuXrFq+Re0ZVj/cROu7X2wf+SafeeFXhMx1yjnRpzJQbdHX5Lbp09Pgebxc+E9JvmnfpRPNuffDOMUmSc6RLE6bP0ZVTSlkoBFkvUTtK1F4mTJ+jwopFuujiYZKkYMsevf/Wr3Rs7zZTu4jdJ5FPPj6vE8179P5br5na9fiSWbr86mt7bcexbfm3b7ea2uSYKTfo8qu/rNHe63Rw0/2Dfs8AhqqNjS+5WSea9+id15p0OtAsSbps3ES5b/qmxpfc3Gv7GUwbStVxxN7P+JJZuvHOx/s8b/dnPtpPPj6v0/6Dev+tX+n3He8ax9Z1fFd4r+vx/JuojQdb9qj9F9t1OtDc4/EC3a1cebdpLswuhYWTjMu1tfepsnJe/GfHcFiNjU06cuSI6T7Ky8t0zTXXJLzNd76zVC0tLcb23r2NysvLS3hssfsWFRXp6ac3GtcFAgG99NIu/fM//1ptbZ3tzuXK0/Tp0zV16lRNm1Yip9PJE9xPhJgAACAt/vjRuYQhaPhMh47t3aZTb7yqWffUJwwygy171PLcYwqf6Yi77dEddTq6o05f+fYPVPj12yk0csL53/1rj+3l6I46/e7ErzVl/nf1RsOPTMFC7D7v+Q9q9uqtCQOQD0+f0KtPrjDCx1gnmnfrRPNutb38U91wx2MJ22TbKz4d3FQb/4Ux2p6P7d2mOQ9t44mEZZ052WYKDbt88M4xHdxUq3dea9KM72/oMUAcbBtK1XEMpRPNexK2867j++CdYzq6o04zlq9TftHNvd7Xr7Zt0NEddbzwkDbBYFCrVt1rBIixGhub1NjYJJ/vZ3rkkYeUn59vXHfTTTNMIeahQ809BqSx+1177VeMy9u3v6A1ax6Mu01HR0gNDT41NPj0/PNbWWF9AAgxAQBAWnT/gpYo/PjNwZf05QXLTH8PHffrlfV39Xn/v/zx32rkmC9qdOE0ip08V42vfZ9FjmUET8cFfX3ZPx1o7rNNffDOMZ1o3hPXGyx8JqTdDy+K+1Eg0e13P7xIVeteMgUooeP+HoMNDEh1ja+9NIuONyfaalfP5d7a2MFN9yfsLTjYNpSq47CKV9bfpVsmTJZzZOLeam9u39hnrYBUCoVCWrJkqTo6Qr3u19bWpiVLluqFF7YbvSInTTL3LG5vb09429bWVtP25MmdPUMDgUDCABOpQYgJAACSduOdj+vGOx8f8PC08SWzNO6aGXKOHCVJ+vd33zaFIccPvBgXYr7R8CPjsnOkS9d/50EjqDzdeki7H/5r4/ojP1lPiNk/n5F0PWWwpu7t5e0D/xQXePS1z5mT8W3ztR+bezV3DWe96OJhCp8J6eiOOuM+wmc61Lqz3tQu3z7wT6Y2OWP5etNw0tBxvzra39BFn/3coN8zbGJM9B/SbNLcGo2aOFX/LRowvvvGPtMPCCead2ty5dK4npSDbUOpOo6h9mdXXqU5D22LGy4eOu6P6wX+7tEDPQ6f76rVaE+Jxl1bJkn6tHMYL0AkZe3aR7V27aNxw8pbW4/2eJt169abAsza2vtUXl4mp9OpUCik+vrNamjwSersHfnMM8/qjju+K0nKz8+X2+02enA2NPh0zz2r4h7jjTfeNC67XHlGr8qXXtpl+vsPf/iYqcdlIBDQm28e1bBhtIGBIMQEAABpC2S69yTJm+A1DaPr3lPjw9MnTF+SJlcuNYWUowun6Svf/oF++eO/ldTZ6+XD0yfS/kUPSEd7ufSKL5gCymT2+WP4XFybig0TJ82tMQUPzpF5mrao1jT/3dEddab5NU+98aqx/5du/nZcwJE3wcsctciKNtY9WMyb4NWwz/+F6ce1jvY3TeeUVLShVBxHOvTUjvMmeFVU/b/lu2u28bf333qtxxDzsnET+xxWD6RKMBg0hZ2LFt1uGg6el5ene+5ZpffeO20MB6+v36y/+qvbjN6Y5eVlpmHohw8fVnFxselxmpsPG5dnz77QFg4cOGBcXrBgQdyQcY/HwzDyQWB1cgAAkFGf/tzwHq/raH/TtH3lpOlx+7gKpvR6GyBXJDMnXl/7vPvmPtP2xJkLEu5XcGOlafu0/6BxmWGhyGXdzzPvv/VayttQKo4j0/oTSA6/fGxOBJhvNf74fofDERnqfz/4wf96lZY4cAcOmNva/PmJw/W5cytM24cOXfjRfPr060zXHT/+tmk7FAqZQs4JEyZc+BzaxxB2DA4hJgAAsKzYL22XjZuYcL6t7j1FPvnD7ykc0IPYRUicI109zmF36RUTTNt/DJ83tcUuv97zY314+gSFRc5wjswzvcbPvX8y5W0oFccBILHYcNHlyutxZfGrrvqCafv8+QttND8/Xy7Xhdt1Xx3d7zfPhzltWolx2e12G5e3bdumYDDIk5JCDCcHAACWFdurcvjlY5O6TaKVYgHEtylXweQe9+veayp2qOgV3uuMdhY+0yHfXbM1ceYCjf3yV5mTFjlh+OVjjdd493NKKtpQKo4jkz48fUKf/OEj270uLvrsJacknRzqx3E6h42QVEhLHBi/329c9np7ntokdkVySTpy5Ihp2Pns2bNVX79ZUmcwGgqFjED0+PHjxn5FRUXGMHRJKikpNoLUjo6Q5s6t1Pz5VbrhhtK4IenoP0JMAABgWbHDVjva39Qvnvg+RQFS1KYG6gvX/aWOH3jRdF/H9m7Tsb3b5Bzp0uTKpf0OawA7taFsE2zZozMn/0W/O/Fr0zzVdnPV9K9v+X9Prlg91I8TCPhLJTGkfIBSNZx7ypTJRogpdQ437wo5Y+fDvOmmGabbfe1rs7Rr1y7TcTQ0+NTQ4JPLlafFixebwlL0DyEmAADImi+OsYspAMiMS0eP1/XfeVD7n74vLtAJn+nQwU21eue1Js26t55iAVnsw9Mn9OqTKxjhAFsqLi6Wy5VnhJHt7e2SOhcOih2yPmmSubdnfn6+7r+/Vg88sCYuUO3oCGnNmgf18suv6OmnN1LkASDEBAAAsK+zkrZY5FjGSlrIU5IdRhdOU9W6l3SieY/aXv5pXMhxOtCstld89MhMzn5J+7LoeGmrNhA+E9LuhxeZfqiYOHOBRo5169POYXKOHKUX711AoZDTpk+froYGn6TO3pT33LNKR49eGK7udrvjhqVLnQHoCy9sV2Njk3y+n5lCT0lqaWnR9u0v0CNzAAgxAQBAVhhfMks33vk4hUits3VVBautcCA1vvZSEYxY1qedw+P+dtHFw+SeUSX3jCqFjvv1RsOPTENNBzIHoE3ts0o7pK3Gc450DVkbysRxJOvY3m2mAHPWPf/AnLfIaZdccknc36ZOnWqEmJIUCASMHplS5/yXPbZZp1OVlfNUWTlPgUBAGzc+rZaWFuP67nNwIjmsTg4AACxrtOfCao+szAoM3viSWcbl2AVKuuu+4vjIse5e7zdvglczvr/BFLQw/QOyVW+L9wxVG+rvcQy19/wHTediAkxki/LyMuNy7CI/3XVfNbygoCBun9hVxyXp7bd/owMHDhjbU6Yk1y49Ho8ef/yHva54juQQYgIAAMv6/PgvGZc/eOeYwmdCFAUYhEv+/ArjcvhMR49t6sP3jpu2P/f5UX3e90UXD0t70AKkWvhMyNQD8bJxE9PWhvpzHEMtdoqIT39uOC8MZI3Ro0cblzs6QgqFErfRt9/+jWl71Kj43s5Op1Pz518YUeDz/cw0z2VhYfKLyDudzl5XS0dyCDEBAIBljZo41bR9dEcdRQFS2KaO7d2WcD//zguL8jhHupLuhRXbYzrdoQuQCt3bxMgxX0xrG0r2OLr740fnhqwmjIRANuneOzJ2OHisZ5/dYlx2ufJUXJx4aPjUqRfafOzclvPnV8npdPbr2E6dete47Ha7ebIGgBATAAD0W/e5vYIte4zLn3x8PmWPM7pwmikIObZ3mw7Vr4kbphc+E1KwZY9+8cT3FTru5wkCkmxTR3fUqe0Vn9Fuw2dCOlS/xtQLa3LlUtN9/OKJ7yvYssfUA+2Tj8+r7RWf6XZXeK9L+3sGkKxz75/U6dZDca/h2B/LLhs3MS58TEUbSsVxSOYpV7oW0wod9yt03G+cEwc6rUPsfX/wzjFTm5XEuRZp133OyqamvRc+B4bDxuXi4mJTQFhfv1nbt79g7BMKhfTww4+YAsnFixf3+Lheb+LelomGn0vSypV3q6lpr6kHaDgc1vbtL5ges7f5NNEzFvYBAAD91n1ur1fW3yWtv0tS6hfgKbn9PtMKqMf2buux54skfenmW3mCgH60qYObanVwU23CfUd7SuIW5znRvDupYGTizAUZec8AkvHBO8e0++G/7nWfa761fEjaUKqO4y88RabFtHo6hoEouLHSdN+vrL9Lo3+xXZ/+3HD98aNzpuuAdOgeGq5YsVIrVqyU1DkP5tq1jxrXrVp1t2699cL6Y2vWPKg1ax5MeL9FRUW9LrCTl5enoqIi06I8Uvx8mV0aG5uSmu8ydpg6kkdPTAAA0G/jS25O20qpeRO8mvPQtqQe77JxEzVs5CieIKCPNjVj+bo+29T4klma8f0N/b5/50hX9P7zMvKeAaTCjOXrehwCPtRtKNnjcN/0P3o9hvElszRpbs2AHje/6GbTIkZSZ2/PE827dTrQLOdIV9z1wFAqLy8zLYzTG4/Ho8ceW9vn/uXlZXr88R/2eX833TTD3PbcbuXl5Q3o/+Fy5emxx9YO+PZ2R09MAADQbxddPEwVD/1Ux/Zu0/EDLxqLD4wvmaUvls5N+ePlTfCqat1LOtG8R++/9ZqpF9hl4ybqz68q1OVXf1n5RTfz5ABJyC+6WaO916nt5f+rfw20GL2qnCNdGjPlhl7bU9W6XXr3zX364J1jprY42lOiz4//kibOXGAKMDPxngH0ZbSnROOuLdM7rzUZr//Lxk3UFd7r9IXr/lKXjh4/ZG0oVcdx0cXDVLXuJbXurDe1q4kzFxiPHzruH/B80jfe+bguv/rauGMbXzJL7pv+h0407xnwcHWgv5xOp557bqsaGnzatWuXscBOeXmZ5sz5etz+ZWUzNW1aiXy+n+m1135p9KR0ufI0ffp0TZ06VWVlM5N67O69LmNXQO9ux47tOnDgoNra2kw9MouKinT11RM1f34VAeYgOCKRCFUAYM83QIej6w1wfyQSKaUi9lXjay+V9CqVgA3tr6sqKKUdAhn1QF1VwWrOmUNv0/wL0xpkchoDqxwHrNlWAwE/50OLCQQCpuHpTz319z0uBITBtTGPx9trG2M4OQAAAAAAAJDAm28eNS73tpI5hh4hJgAAAAAAANBNOBzWtm0XFpScPXs2RckgQkwAAAAAAAAgRjgc1jPPPGvMvylJU6ZMpjAZxMI+AAAAAAAAgKTCwkkJ/15eXsZQ8gyjJyYAAAAAAADQA5crTzU1iylEhhFiAgAAAAAAAJLmz68yLrtceVq06HY999xW5efnU5wMYzg5AAAAACDnLW5o4zgA9Omee1bpnntWUQgLoicmAAAAAAAAAEsjxAQAALCvk5QAAAAA2YAQEwAAyU8JYFMnaYcAAFjqnHmWUgOJEWICAGyvrqrgrKT3qAT4QpbxdniKpwQ25Od4AV77XTwer1/SOcoNG9rX1w6EmAAA26vxtY+QdDGVgM2ck7Qz2z68AjnYDrPqdR/9wWE/Tx1s5lRdVUE6A/ydlBx2Ox96PN4+z4eEmAAAW4sGmPskXUY1YDNbomGElazmaYHNbLBgO6StApl/zdPGYLvzYTI7EWICAGwrJsAspBqwmVNW/IJUV1VwUtIDPD2wgz/9xx9OJPulzYJtdZ+krTyLsIn9dVUFW9L5gB6Pl/Mh7KTV4/Em9bmUEBMAYEs1vnavOuc2IsCE3ZyTVGHV3l91VQWrRTiCHPen//iD9j72N+M3zXdXZ/F/Y5mkVp5N5LhWSRWZeOBoqMP5ELnuVH/aGCEmAMB2ogHmPkljqAZsZr8kb5rn9eq3uqqCatEDBTnq3989fr5h2Sz9669fk6T1Dodji8PhGJFt/4+6qoKzdVUFXklP8KwiR70oqTSTP/p5PF7Oh8j5z6XRnsdJcUQiEcoGwJYcDkfXG+D+SCRSSkXsISbAHJ7kTT6RdBGVQw58EdtSV1WwM8va61h19vaqED86IDfa4Ya6qoJ9Dodji6SFMde1SqqIRCIns/E/Fm2rq6NtdThPNbJY16J3W6LTJlhCIODnfIhcamP7JG1IZiGfuO/whJgA7IoQ034GEGC2KvoLfPS2I6gisow/SxcN6a0N0w6RE+3Q4XBUS3q22xe7ikgksi8H2iqfq5B1rBRa9iUQ8HM+RFaeDz0e76A+lxJiArAtQkx7GUyASfUAAEP0WSTRuWl5JBLZQHUAADBjTkwAQM4jwAQAWFEkEvFLGivzAjlZO08mAABDiRATAJDTCDABAFYWiUTORiIRr8yrEC+UtM/hcIylQgAAdCLEBADkLAJMAEC2iEQi1ZJui/lToSS/w+EopToAABBiAgByFAEmACDbRCKRLZImqXORH0XPYa86HI5lVAcAYHeEmACAnDOAAHOrCDABABbAPJkAACTG6uQA7PsGyOrkOWkgAWZdVUE1lQMAWPCzyhZ1zo/ZpVVSaSQS4Uc3AIDt0BMTAJAzCDABALmkh3kyTzocDi/VAQDYDSEmACAnEGACAHJRD/NkHnU4HJzDAAC2QogJAMh6Nb72ahFgAgByVHSeTK/M82Q+Gx1uDgCALRBiAgCyWjTAfFYEmACAHBaJRE5KKlXnYnRdFjocDj8L/gAA7IAQEwCQtWICzGQRYAIAslYkEjkbnSdzecyfmScTAGALhJgAgKxEgAkAsKtIJLJB0g1inkwAgI0QYgIAsg4BJgDA7iKRyD4xTyYAwEYIMQEAWYUAEwCATsyTCQCwE0JMAEDWIMAEAMCMeTIBAHZBiAkAyAoEmAAA9Ix5MgEAuY4QEwBgeQSYAAD0jXkyAQC5jBATAGBpAwgwlxNgAgDsinkyAQC5ihATAGBZAwgwb6urKthA5QAAdsY8mQCAXESICQCwpAEGmFuoHAAAnZgnEwCQSwgxAQCWQ4AJAEBqME8mACBXEGICACylxte+RQSYAACkDPNkAgByASEmAMAyogHmwn7chAATAIAkME8mACDbEWICACyBABMAgKHHPJkAgGxFiAkAyDgCTAAA0od5MgEA2YgQEwCQUQSYAACkXy/zZO5jnkwAgBURYgIAMoYAEwCAzOlhnszrJfmZJxMAYDWEmACAjCDABADAGqLzZM7VhXkyx0jaxzyZAAArIcQEAKQdASYAANYSiUR2qnN4edc8mcPVOU/mBqoDALACQkwAQFoRYAIAYE2RSMSvziDzxZg/38k8mQAAKyDEBACkTT8DzHOSJhFgAgCQPtF5MiskPRDzZ+bJBABkHCEmACAtBhBgltZVFfipHAAA6ReJRFaLeTIBABZCiAkAGHIEmAAAZB/myQQAWIkjEolQBcCCanztY6MfGr3Rf0ix35349fWS9N8+c/HZEX8xvpWKpNxZSe3R129ZkrexVIAZCPhph8iFduiXtNPj8fLDAICBfWnsnA9zi6Q5MX/eL6kiEomcjTlnVkTPl2OpGrLQyei/rD1n0g6R6+2QEBOwmBpf+whJG9S/hU+AXGCZADMQ8NMOkYtOSVrm8Xh3UgoAA+FwOFZLuj/2fWXp0iVLa2oWr1DnvJlArtgfPWdmRZgZCPi90c+utEPkdDskxAQspMbX7pW0T51DdQA7sVKASTtErtvq8XirKQOAgXA4HBXq7JU5fOHC/6klS74Tufjiix1UBjnqNo/Hu8XKBxgI+KvVGWDy2RU53w4JMQGLIMCEjRFgAun3hMfjXUYZAAyEw+Hw3nLLt3asWPG/xlIN2IBlg8xAwF8haQdPEezSDgkxAYuo8bX7JRVSCdiM1ebApB3CTm7weLz7KAOAAZwvR0QikVMOh+MSqgGbfF71ejzek1Zrh+qcO5Af32Gbdsjq5IAF1Pjaq0VwAnueiKwUYNIOYTdbKAGAAVpGgAkbGS5ptQWPiyHksF07JMQErKGCEsCGaqwSYEZV85TAZsZEp1AAgP5iOgrYzcJoz0e+QwIZbIeEmIA1zKEEsCG3xY6H1RxhR3wBAtAv0R8/6P0FO/JaqB2W0g5hR4SYQIbV+NrHUgXYlGVe+/RGAwAgaSMoAWyqlBIAmUWICWTeWEoAXvt8IQP4QgYAAAD0jBATAAAAAAAAgKURYgIAAAAAAACwNEJMAAAAAAAAAJZGiAkAAAAAAADA0ggxAQAAAAAAAFgaISYAAAAAAAAASyPEBAAAAAAAAGBpn6IEAAAAAACYrVx5txobm4zt1tajFIX6AcggQkwAAAAAACyusHCScbm8vExr1z5KUQDYCiEmAADISsFgUOfPnze2PR4PRQEAAOCzIZ8NcxQhJgAAyEp1dZsYpgYAAAA+G9oEISYAAAAAABZXW3ufcXnYsGEUBIDtEGICAAAAAGBxlZXzKAIAW/svlAAAAAAAAACAldETE0DW+eTj8zrtP6j33/qVft/xrk4Hmo3rLhs3UVd4r9OVU0qVN8Gb8Pab5ruNy9ctXiP3jCoFW/ao/RfbdTrQrPEls3TjnY+bbhM+E9JvmnfpRPNuffDOMUmSc6RLE6bP6fWxgFwUuzpqbe19qqycp0AgoJde2qUDBw6ooyMklytP06dP14IF31R+fn6P9xUOh9XY2KQjR46Y5jAqLy/TNddck7DXycqVd5v27e24AADoTTAY1M9/vlvNzYfV1tYmSSoqKtJNN83QuXO/T+o+QqGQ9uxpVGNjk3EfLleeZs+ereuvn97r4iJd589//udfm247ffp0TZ06VdOmlcjpdMad5xKtTp7oPNjUtFc7duxUS0tLwtsM5thTVT9gsAbz2bC/n0W/852lamlpMbb37m1UXl5ewuOK3beoqEhPP71xwO0fnQgxAWSdE817dHBTbcLrPnjnmD5455iO7qjTjOXrlF90c5/396ttG3R0R13PH85a9qjluccUPtNhPuGd6dDRHXU6uqNOX/n2D1T49dt5cmA777//fsIPjh0dITU0+HTgwAE99dTGhEFmMBjUqlX3Gh/aYjU2NqmxsUk+38/0yCMP9RqEAgAwEE1Ne7Vixcq4v7e0tJhCir7uY926deroCMWdB+vrN6u+frOWL1+m6uqFcbfdvv0FrVnzYNzfu86hDQ0+Pf/81gGvsPzkkz9Sff3mITn2VNUPyKSBfBa96aYZptf3oUPNPYajsftde+1X0tr+cxXDyQHkrFfW36XwmVCv+7y5fWOvAWbouD96Px293s8vf/y3Ot16iKLDdurrNyf85Tv2g9jPf747vm2FQlqyZGnCD42x2tratGTJUoXDYYoNAEiZw4cPJwzg+iMQCGjFipVxIWB369dv0OHDh+NumyjASJVNmzb1GmAO5thTVT8gkwb6WXTSJPMIvPb29oS3a21tNW1Pnjwpbe0/l9ETKVdvTgAAIABJREFUE0DW+bMrr9Kch7bFDeEOHffrjYYfmYaXv3v0gNwzqnq8r65wcrSnROOuLZMkfdp5YbXHNxp+ZFx2jnTp+u88qNGF0yRJp1sPaffDf21cf+Qn643rADspLy/TV7/6VY0a5ZIkvf32b0wfzHbt2qU77viu6Tbr1q03fXGqrb1P5eVlcjqdCoU6e4A0NPgkdQahzzzzrHEfa9c+qrVrH43rAdraepQnAwCQlL/7ux+ZtmPPQ10hwyOPPNprwLFx49PGZZcrT/ffX6vi4mJJnSHfkiV/Y3q8rusk6aWXdplu+8MfPmbqcRUIBPTmm0cHvAp51zm2a2i3ZF7RfDDHnqr6AakykM+GA/0smp+fL7fbbby2Gxp8uueeVXH3/8Ybb5raWGz7Hur2n8voiQkg6+RN8CacgzJvgldF1f/b9Lf333qt1/u6bNxEVa3bpVn31ss9o0ruGVXGEPQPT58wBaKTK5eaQsrRhdP0lW//wNj+4J1j+vD0CZ4g2ErX/FplZTPl8Xjk8XhUWTlPRUVFcV+kugSDQdMHzEWLbldl5Tzji09eXp7uuWeV6T7q6zfTGxMAkBKHDx82hWtdc+XFzj3n8Xg0ZsyVPd5HMBg0DRVdvHixKegrLi7W8uXLjO22tjYFg0Fj+8CBA8blBQsWxA0Z9Xg8qq5eOODpVNxut3bs2K6nn96oysp5qqycp7KymSk59lTUD8ikwX4WLS8vi3tP6a65+cLfZs+ebbpuqNt/LqMnJoCccuno8f3af/jlY3u8TUf7m6btKydNj9vHVTAl7jb9PQa7+s8//fEzDoej1ArH8vD/Z+/+o6Oq7/3fv3D16tczaPQEOwONAqFwMmAnw4+iSSDGGkngcOoPznDKUY+49ED1nH4V7QK/oNSi9CueCthj0XhixR+36UmKaKWQIF4xEIO0wDCrJGkwASSlM9UUUVJvvXfd3D9INnvPTMIkmWH2zDwfa7HW/No7O589b/bMK58fq5/wzp3795yUOMrKurTP5+rrd1nuz58fvbf0LbfcHDHnUO8XMAAABqu19bDl/owZRQPex4ED/nPuwzx8tHeb3lDiXMO4h2r06Kv6DECGeuzxaL9U1N7ePiY/fzKfXdPAUD+LFhfP1Lp16y3/p5j/EBAKhSxB/4QJE6zfGRNc/+mMEBMA+mDuxTli7EQ5siNXnQvvEfrlX1iFMVZfnPqzS9K7djiWnTt3ig+C54/5Q53L5exzRcfx479uuX/69GkaDwBw3q5D/dm7d69x2+12R91HeO+qzz//3LJN73FUVVWpuHjmeet1NdRjj0f7paIPPth7p6Q7+ezKZ9Hc3Fy5XE4jjKytrbMsgOX3W+fDDA/6k1n/qY7h5ADSxsmONoVa/XHbn7knZtaoMTFt88mRJk4EcA5+/9k69Xq9fb4u/MOc+UsXAACJvg7Fuo9Yh02bg5OiorO9toLBkG65ZZ5Wr/5R1GGpifz9B3Ps8Wg/INU/i5qHiDc3NysUOtu7srW11bhdUFBgmWoh2fWf6uiJCSBltTduU+fR3+vjtt9Z5q6MF/OK5MGW/XrnmYdo9Dj6Py52fCppox2OZfTo0WNkk7+sZwKG0AAAUv06ZN6H3+/XsmUPD2j7v//7OdqyZYtlP9XVNaqurpHL5dSiRYs0b96tCf/9B3PsmXodHz36qvck7eSzK/8HSNLUqVNUWfmicX/37gajZs3zYfYurGWX+k91hJgAUs7Jjja9+59Lz2uvx67OoNoattL4cXSR49JPu7u7H7PDsQQC/hI+CAIAgMEIBkOWRUJikZubqx/8YKV++MNVEYFKMBjSqlWP6+23d+j55zfY7tgzVWFh4U4+u8L0frAMKW9paZF0ZtEgc8/lyZO9tq3/VMRwcgAppaszpK2r77EEmBNnLdDMRatUumStbnqiikYCAACA7RUWFur11zdp5cpH5Xa7I55vbGzUpk2v01CATRUXn134tbq6RpJ14Sy3293nXJfU/+DQExNASmnaXmUZ5j1nxX8pJ39Gwn/uuKI5uuH+pzkBQBJdeumlNAIAwHbKy8u0Zs2Tg9rW4XBo3rxbNW/erQoEAtqw4XnLash79+5N6LDSoRw7kOmfRadNm2aEl5IUCASMHpmSde5LO9Z/KqInJoCUcty/y7id4ylKaICZ4zm7itypE0dpfCCOX5h6mSdWD9fe3m65n5eXR+MBAIbM3Oupv+tQfwoKCozbx459FJfj8ng8evrp/5DLdXal5EQM9R7qscej/YB0+Cwavur44cMfqr6+3rg/deoU29V/qiPEBJBSzMPIL7okK6E/64pxV1t+blcni5EA8ZCTk2PcDgZDltUcwz8Imo0c6aLxAABDZl6Ru7/rUH8mTZpo3A5fmXgoHA5Hwlf8Huqxx6P9gHT4LOpwODR/vs+4X1PzS8scl/n5+bar/1RHiAkgZSW6d+TIidMs9w9srqDRgTgI/6u0eRiO2UsvbTRuu1xOFRYW0ngAgCGbPn265f7u3Q1DvpaZVykeKnPvyGhz5cX7OjzQY49H+wHp8ll02rSz3xnNC/rMn++Tw+GwXf2nOkJMACnFPMT7kyNNam/cZnk+1Bq/IS05+TM0YuzZv1Q3ba/S7spVOtnRZnldV2dI7Y3b9M4zD8X15wPpqrCw0PKhrLLyRW3a9Lq6urrO1HEopNWrf2T5ILho0aKI/YTPS1RXt/1sXfbsCwCAcOFDQFetetxyHerq6tKmTa/3O8w0/FpWXV2j1at/FDH8NBQKqa5uu5Yte1iBQMB4fNmyh1VXt93SA6z355qvf+eaUy8e1+GBHns82g9IhFg/G8brs6gkeb3Re1v2Nw1SMus/1bGwD4CUknfDPHUEzv61d8e6B5XzziZddEmW/vr5Kctz8VB096N685EFxv2m7VVq2t73CuhXz76DkwTEYPnyh3XHHXdavgCtWvV41NcWFBREndQ8/MPh0qXLtHTpMkksVAAA6JvT6dSSJQ9o3br1MV2HYr2WVVfX9NmjS5Juu+2fjdu1tXUxzXdnHqqayOvwQI49Xu0HxP274gA+G8bjs2hvPRQUFFgW5JEiw36zZNd/KqMnJoCUklswW+OK5lge6wg0qK1hqzoCDXJkuyKeH9KH3Ale3fRElRzZ556Lb8TYiRqePZKTBMTA4/HoqafWWCYvj6a8vExPP/0ffT53ru0BAIjG5/tHywI34Vwup2Xxj76uZa+++nJM1yK32y2nM/Zrlsvl1FNPrRnQNgO9Dg/l2OPRfkC8DeSzYTw+i/a68cbSIdX7+a7/VEZPTAAp54b7n9aoSdfqyJ46o+fliLETNa5ojtw3/pPaGraprWFr3H6ec4JXvrVvqa1hm04c2mPZ94ixE/XV8fkaNembyi2YzckBBqCsbJZmzChSTc0vtWfPB8ZfsF0up4qLizVt2jSVlc3qc3uHw6FXXnlZ1dU12rJlizGRenl5mW666ds0MACg32vI889vUF3ddm3e/IZxDXK73SoqKtT8+T6FQqFz9pbyeDx6/fVNqq2t0969ey2vd7vd+sY3ro56Pdu8eZPq63epubnZsk1BQYEmTZqo+fN9CQ8wBnvs8Ww/IN51PZDPhkP9LNorvNfluQJ8O9R/qhrW3d1NKwBJtLimpUTSu7QEMtB7Fb68EjscSCDgpw6RsXXo8XhLaAYAXDOBc/qhx+N9jDpE5PkIWIamP/fcT1mQMkEYTg4AAAAAAAAMwv79B4zbfa1ijvggxAQAAAAAAAAGqKurS1VVZxd+nTt3Lo2SQISYAAAAAAAAwAB0dXXpZz97yZh7U5KmTp1CwyQQC/sAAAAAAAAAMcjPnxz18fLyMoaSJxg9MQEAAAAAAIBBcrmcWrx4EQ2RYISYAAAAAAAAQAzmz/cZt10up+6552698srLys3NpXESjOHkAAAAAAAAQAxWrFiuFSuW0xBJQE9MAAAAAAAAALZGiAkAAAAAAADA1ggxgeT7lCYA730ASXKUJgAAAEAqIMQE+AIJJIvfLgfi8Xh3cjrANQgAAKTCZ1cgUxFiAsm3kSYAHwRt4SCnBNQhAPSPP/yBaybHAiQLISaQRItrWjZKuomWQAY6VeHLe8Nmx/QGpwWZVocej5f3PYDBeJkmQIZ5z+PxHrXLwXg83k8lvclpQabVISEmkCQ9AeadtAQy1HqbHtMpTg2oQwDg/w8gzGPUIZD8OiTEBJKAABMZ7mCFL892HwR7/qK9kNODTKlDj8f7GM0AYJDXTL+kH9ISyBAv23EahZ5jog6RKZ7xeLw7CTGB84wAExnuoKQSG38pe0PSXZwmUIcAcM5r5mNiWDnS38sej3chdQgkvQ4fkJgTEzivCDCR4Z6RVFLhy/vU5l/KNkq6XtIxThnStQ57eh4DwFCvmQslLRHTsSD9nJL0QzsHmNQhMqQOl5jrcFh3dzfNApwHAwwwT0laK2mKJK+k0bQgUtR7OrN64voKX97RVDv4QMC/UNLN1CHSpQ7ttCgBgPQRCPgv05kpWXqvmVm0ClLQqZ7r5RuSNqbaH/yoQ2RCHRJiAufB4pqWhZJeGkDRllT48vy0HAAAAAAAAMPJgYQjwAQAAAAAABgaQkwggQgwAQAAAAAAho4QE0gQAkwAAAAAAID4IMQEEmCAAaYkLSTABAAAAAAAiI4QE4izQQSYd1X48t6g5QAAAAAAAKJjdXIgjhbXtJRIencAm9xV4cvbSMsBAAAAAAD0jZ6YQJwsrmnxShpIj0oCTAAAAAAAgBgQYgJx0BNg7pSUFeMmBJgAAAAAAAAxIsQEhogAEwAAAAAAILEIMYEhGESAuYQAEwAAAAAAYGBY2AcYpEEEmC9X+PIW0nIAAAAAAAADQ09MYBAIMAEAAAAAAM4femICA7S4puUySX5Jo2PchAATAAAAAABgCOiJCQxAT4C5UwSYAAAAAAAA5w0hJhAjU4CZH+MmBJgAAAAAAABxQIgJxIAAEwAAAAAAIHmYExM4h0EEmAcrfHleWg4AAAAAACA+6IkJ9GMwAaakEloOAAAAAAAgfggxgf7t1AADzApf3qc0GwAAAAAAQPwQYgJ9WFzTslEEmAAAAAAAAElHiAlE0RNg3hnjywkwAQAAAAAAEogQEwhDgAkAAAAAAGAvhJiACQEmAAAAAACA/RBiAj0GGGCekrSQABMAAAAAACDxCDEBDSrALKnw5flpOQAAAAAAgMQjxETGW1zT8pgIMAEAAAAAAGxrWHd3N62AjLW4pmWhpJdifDkBJgAAAAAAQBLQExMZiwATAAAAAAAgNRBiIiMRYAIAAAAAAKQOQkxknAEGmJJ0MwEmAAAAAABA8hBiIqMMIsC8q8KXt5OWAwAAAAAASB5CTGSMQQaYG2k5AAAAAACA5GJ1cmSExTUtXkk7JWXFuAkBJgAAAAAAgE3QExNpjwATAAAAAAAgtX0l2oOLa1pKJN0syUsTIYV9KumwpEWSLo1xGwJMAIZAwM/1EOlyPdwpaaPH4/2U5gAAAEAqsgwn7+mxtl7SdTQNMhABJgBJUiDg90raKCmf1kAaOSVpvcfjfYymAAAAQKoxQsyeRU/WK/Yht0A6eabCl/cAzQAgEPAv1MAWAQNSzXuSbqZXJgAAAFLJBZLRA/MlEWAiM71MgAlAMoaPE2Ai3V2nMz2NAQAAgJTRu7DPGzQFMtTLFb68hTQDgEDAf5kIdpA5burpdQwAAACkhAt6hpGPpimQgQgwAZhxPUSmeYwmAAAAQKq4oOdLG5BpthBgAgjD/wnINKN7plAAAAAAbO8CsRI5MtM+mgBAGFYiRyYqoQkAAACQCi6gCcCXNgCZjt5oyGCX0QQAAABIBYSYAAAAmctLEwAAACAVEGICAAAAAAAAsDVCTAAAAAAAAAC2RogJAAAAAAAAwNYIMQEAAAAAAADYGiEmAAAAAAAAAFsjxAQAAAAAAABga4SYAAAAAAAAAGztKzRB/HQc3K3f79ystoatkiRHtkujp16vybcsliPbSQMBAGwvP3+ycbu8vExr1jxJowAAAABIuphCzHeeecgI5gZq5qJVcpf60r4hD/7qRX3w2o8tj3V1BtW0vUrji79NiAkAAAAAAAAMEsPJ4yDU6o8IMAEAAAAAAADEB8PJ4yDYss9yf/Iti5V/8z268OLhNA4AAAAAAAAwRDGFmFPm3aerZ98R8fibjyyw3L/piaqI1wzPHpn2jfjJkSbLfQJMAAAAAAAAIH5iCjEvzxkX086cE7y0qESACQAAAAAAAMQRc2ICAAAAAAAAsLXzNifmC/Pdxu3eFcvbG7ep5Z1N6gg0aFzRHN1w/9P68ovT6vDv0olDv9FnwY/UEWgwthsxdqKu9M7UVVNLovb6jPYzQq1+Ha7/lY7te1ddnUE5sl0aPfV6TSq/rc8epr3b/OnwQWOoeO92oyZ9Uznembrw4uF9rtpuPo6bnqiKONYvvzittoZtOnFoj2X7cUVzNGrStf2u5h5rOw6kPSYU32QZAt/euE0nDv1GTdurjN89/DXhujpD+rBhi9oatlrabELxTX2er4H+PgM5NwCA+AkEAnrrrS2qr69XMBiSy+VUcXGxFiz4jnJzcyOvCV1d2r27Qb/97W91/HiHGhsbjefcbreKigp13XXF8ng8xuPf+c4/q7m52bj//vu75XA4oh7PsmUPq7a2ztjfL37xc+t1PBTStm21qq2tM/bpcjk1d+7ciJ8LAAAAIDUkbWGf31St14HNFRGPtzVs064XVkbd5pMjTfrkSJMObK5Q6ZK1yi2Y3ef+T3/8h6ghY1dnUE3bq3Rs37uas6IyIshs3lET9ef3bte0vSpqMBmrkx1tevc/l0bMo3nmd9+qtoatan77F7r+e0/FNIy/r3YcSHsc2Fyhj9t+p6nz/137qp+1BMfm1xz379Lcx16OCAnbG7ep8ZWn1NUZjLrdgc0Vuub27yv/23cP6fdJ9LkBAFidOvWZJTDsFQyGVF1do/r6ej333IaIILO2tk6rVj0e/f/y5mY1NzersvJFPfXUGpWVzZIklZeXWULMgwcPqrCwMOo+zMdTXl5mea6ubrvWrl2rYDAUccyVlS+qsvJFLVnygBYuvJMTDAAAAKSQpAwn379pQ0zBW392rHtQXZ2hPp8/sLkiai/JXl2dQX246y3LY6FWf58Bajx0dYa0dfU9UQNMs0+ONGnr6nv05Ren49aO52qPjkCD3nxkQUSAGX5cbQ3bItrszLkI9vvzP3jtx+o4uHvQv0+izw0AIFJjY2NEgGkWDIb0619vHfT+ly5dplDozLV8ypTJludaWw9H3SYQCFjum7cLBAJaunRZRIAZbt269Xr//fc5wQAAAEAKSUpPzN7AK8dTpLHXnulBcZHjTO++v71qfNTedKFWf0QvwY8O1Pc79Hpc0RyNnV4qR88K6X/+6LAlCGutf1PfXPCAcf9w/a+M245sl0qXrLMcR6jVr2DLPl34N5dIkm64/2ndcP/TET0cF1U3Rz2ePa9ZeyvOXLRK44pm68KLh6urM6QDmyuMIdxdnUEdfKPScnwDacdY2uNw/a+MnxfrazqPWn+3fdXPWtrsuu8+rpz8GZKkjoO7tXX1vxrP7/35OuO5gf4+Az03AID4KC8v07e+9S2NHOk68//x4Q8tvSy3bNmi733v3y3bjB//db366ssRw7YDgYA2bHjeMrx89+4GzZt3qzwej1wupxFA1tbWRe0tuX//AeO2y+W0/IwNG563PPeDH6w0enO+//77uvfefzOe/8lPnu2zpycAAAAA+0lKiDli7MQ+h0v3NRTYOcGrgoX/SzUPzjUeO3FoT58hZvhcir37OLKnzghCw3sPHtv3rnH76tm3RxyLc4J3SMPIzUHn5FsWW47dke3UjHtWWuYBPbC5ot95KPtrx1ja4/Irv24JKGN5zV+7Tll+J3OoPGXefZaQMid/hq65/fv64LUfSzrTk/NkR1ufx9vf75PIcwMAiK68vExr1jxpeczj8ejtt3cYQWS0Xo99zTnp8Xi0dOn3dcst84zH9u7dq3nzbpUkFRcXq7q6RtKZYeehUEhOp9Oyjz17PjBuFxcXG7fb29st4eiiRYssIWVhYaGWLHlA69atN/bf3t4edU5PAAAAAPaTlOHkWaPGxBS8hRvMNuEuuiSrz+fONSR6KD7av9Nyf+KsBVFfl3fDPMv9Dv+uuLdjr1gWwOnvNcGW/Zb7V00ujniNK29qv9vE+vsk8twAAAZ4Hc+6dNDb9hcaTps2zXLf7z9ovRZ0dVmCSvPrDxzwW147Y0ZRxP7Dh6yHbwMAAADAvi6gCc4aMXaicft3217TyY62uO3bPA+mI9slR7Yz6usuv3KC5f5fu07btr1OHNpjabtov1PEyux/+cx25wYAYA/hwWNra6vl/sGD1lDT6803bu/du9e47Xa7I3pwSpE9RD///HMaHQAAAEgRKRNinuxoU6g1sT0mrvTONG53dQZV8+Bc7a5cdc4FaWJh7oHoypvS5+vCeyKag0K7Mf9OWaPGxLTNuRY1Ssa5AQCcH+3t7REL85g5HA4VFBQY9xsarIvvmBf7KSgosASVfv/ZzwijR18V0/GYV0MHAAAAYG9fseuBtTduU+fR3+vjtt/1u2J2PH195j+otf5Ny9Dlpu1VatpeJUe2S1Pm3dfvQkL9Scfh0ObfKdiyX+8881BKnhsAQGLU1W1Xa2urDh1qsgwD78+NN5Yarw2fF9M8H+a1115j2c48N6ff79eyZQ9zAgAAAIA0YrsQ82RHm979z6WD7rE3FJfnjNN1331c7z3/aETo2NUZ1K4XVurInjrNeaSSd06Yrs6gZeEizg0AZK729nYtX/7IoHo6Tp5snYakd/Xy8Pkww+e3NAsGQ6qtreNEAAAAAGnEViFmV2dIW1ffYwmpJs5aoOwxbl3kGC5H9ki9+ciChB5DTv4M+da+pbaGbWp++xcRYWpHoEHNO2ro9ZcEnBsAsL9QKKR7773P0jNy/nyf8vLyNHz4cI0c6dIdd9zZ5/a5ublyuZzG9i0tLZLOhJm9XC5nnyugAwAAAEhPtgoxm7ZXWQLMOSv+Szn5M877cVx48XC5S31yl/oUavVrX/WzliHtJw7tOW9B2UWOrJR4I40rmqMb7n86o84NACBSdXWNJcB87rmfqrCwcED7mDt3riorX5Qk1dfXa8WK5ZZFfoqLi/vdvry8TGvWPMnJAAAAANKIrRb2Oe7fZdzO8RQlJcAM55zgVelD6+XIdhmPDWbY9LiiOcZt84I44cJX3c4e47btmyfHc3YV2VMnjqbsuQEAxI95MZ6CgoIBB5iSNHXq2QXwgsGQQqGQDh062/t+2rRpEduYFwQ6duwjTgQAAACQZmwVYpqHB190iX16IF548fB+VxSPxaVfvdK43dUZVFdnKOrrTh5vtdy/5IqRtn3zXDHuasu56+t3svu5AQDEj3kezKysSwe1j/z8fMv93bsbLPNhzphRFLHNpEkTLccQCoU4GQAAAEAaucCuB5aMnn2xHs+IsRMHvP3IidZeI03bq6K+zv/G2YVpHNkuW/RGjfV3OrC5IiXPDQAgMQbbI9LhcKi8vMy4X1PzS+N2QUGBHA5HxDbm3puSjOHoAAAAANKDrUJM8/DkT440qb1xm+X5UKs/oT//nWceUnvjNkuPwi+/OK3mHTWWXqJXemcO/HfLn2EJ2A5srlDzjhp9+cVpSWcWNdpducryc6bMu8/Wb57w36lpe5V2V66KGBLf1RlSe+M2vfPMQ4M+h4k8NwCA+DEP625ublZd3XbL84FAIKb9TJ8+3bKfXjfeWBr19YWFhXK7z07BUl1do9Wrf6T29nbrZ4lQSHV127Vs2cMxHwsAAACA5LPVwj55N8yzLNKyY92Dynlnky66JEt//fyU5blEaGvYGtOcihNnDW6F9KK7H7Wsrr7rhZXa9cLKqK/N8RSlxAI14b9T0/aqPnuZStLVs++w5bkBAMTHLbfcbBn6vXTpMm3e/Iaysi7VqVOfWZ7rT7Qh45I0ebK3z22WL3/YsvJ5dXWNqqtr+nz9bbf9MycMAAAASBG26omZWzDbsgCOJHUEGtTWsFUdgQY5sl0Rz59PjmyXSpeslSPbOajtnRO8Pdu7+n3duKI5Kn1ofUq8gZwTvLrpiapz/k7SmaHew7NH2vLcAADio6xslmUouCQ1NjaqtrZOjY2NcrmcEc9Hvb44nZaelZLkcjmVm5vb5zYej0evvvqyXK5zXwvcbrecTq4ZAAAAQKr4it0O6Ib7n9aoSdfqyJ46o+fliLETNa5ojtw3/pPaGrYlbAVq39ot+mj/Tn1ypMnyM3I8Rbpi3NWaOGvBkEOy3ILZyvHOVPPb/60/BBqN39GR7dLoqddr1KRvKrdgdkq9iZwTvPKtfUttDdt04tAeS9uNGDtRXx2fP+Tf63ycGwBAfKxZ86SmT5+ut9/eYfS8dLvdKi8vk8/3j6qtrVNtbd0591NeXmYZSj537txzbuPxePT665tUW1unvXv3Wn6O2+3WN75xtaZNm6ayslmcKAAAACCFDFtU3dxNMyADvVfhyyuhGQBIUiDgL5H0Li2BTLweejxerocAAACwvQtoAgAAAAAAAAB2RogJAAAAAAAAwNYIMQEAAAAAAADYGiEmAAAAAAAAAFsjxAQAAAAAAABga4SYAAAAAAAAAGyNEBMAAAAAAACArRFiAgAAAAAAALA1QkwAAAAAAAAAtkaIiUz1KU0AgP8TAPlpAgAAAKQCQkzwpQ1AxvN4vPyfgExFgA8AAICUcIGkN2kGZKBimgBAmIM0ATLQGzQBAAAAUsEFfHhFhrp+cU3LRpoBgMl6mgAZ5hi9kAEAAJAqLqjw5W0UvU+Qme4kyATQy+Pxbuzu7j5OSyCDPEATAAAAIFX0zom5UNIpmgMZiCATgCRp2LBhl/3P/3n/F3/5y19oDGSClz0eL6NxAAAAkDr9ZogpAAAgAElEQVTf2bq7uyVJi2tavJJ2SsqiWZCJX+YqfHkLaQYgQy+Gw4Zd1nMNzJ8+fbp+8pP13RdffPEwWgbpes3zeLxc8wAAAJBSjNXJK3x5fklesdAPMhM9MoEMZQ4wJWnv3r2nXnnl1bmS3qN1kGZOSbqLABMAAAAp+d2ttyem2eKaljE6M8TcK+kymin+9v3yp2Mk6ZIRo/7vCSW3BGmRhDgqqV3Sg4q9hzE9MoFMugiGBZg6E/KUdHd3+yUpEPD3Xg9LaC2kML8kv8fj3UhTAAAAIGW/v0ULMXFevjj3Nvx73d3dfDlOoEFMlUCQCWTG/8P9BpgAAAAAAPu4gCZAuuuZKqFEsS9exdByIM0RYAIAAABAaiHEREYgyATQiwATAAAAAFIPISYyBkEmAAJMAAAAAEhNhJjIKASZQOYiwAQAAACA1EWIiYzTE2TePIBNCDKBFEeACQAAAACpjRATGanCl7dT0l0D2IQgE0hRBJgAAAAAkPoIMZGxKnx5G0WQCaQ1AkwAAAAASA+EmMhoBJlA+iLABAAAAID0QYiJjDfIIHMhLQfYFwEmAAAAAKQXQkxAgwoyXyLIBOyJABMAAAAA0g8hJtCDIBNIfQSYAAAAAJCeCDEBE4JMIHURYAIAAABA+iLEBMIQZAKphwATAAAAANIbISYQBUEmkDoIMAEAAAAg/RFiAn0gyATsjwATAAAAADIDISbQD4JMwL4IMAEAAAAgcxBiAudAkAnYDwEmAAAAAGQWQkwgBgSZgH0QYAIAAABA5iHEBGJEkAkkHwEmAAAAAGQmQkxgAAgygeQhwAQAAACAzEWICQwQQSZw/hFgAgAAAEBmI8QEBoEgEzh/CDABAAAAAISYwCARZAKJR4AJAAAAAJAIMYEhIcgEEocAEwAAAADQixATGCKCTCD+CDABAAAAAGaEmEAcEGQC8UOACQAAAAAIR4gJxAlBJjB0BJgAAAAAgGgIMYE4IsgEBo8AEwAAAADQF0JMIM4IMoGBI8AEAAAAAPSHEBNIAIJMIHYEmAAAAACAcyHEBBKEIBM4NwJMAAAAAEAsCDGBBCLIBPpGgAkAAAAAiBUhJpBgBJlAJAJMAAAAAMBAEGIC5wFBJnBWlABTkhYSYAIAAAAA+vwu2d3dTSsk50t8b8O/193dXUKLZIaeYPKlAWxySNIkWg4p7JjOBJYbK3x5O/sIMO/q7u7eaMN6vUzSQkk3S7qOU4l0qcMUu25Sh6AOkywQ8FOHSLc6XO/xeP0pWocLwz5HAxlVh4SYSUKImbkGEWQCaeH/+3//n63/fX/5VZ9/fOJq08N2DTAXSlovKYszhzTzpqSFFb68T1PkekkdgjpMokDATx0irevQ4/GmQh0+IOkx6hBp6GVJDwykDgkxk4QQM7MRZCJT/eXkx9r2vxep82iLZN8Ac72k+zlbSGMHJZXYOUBZXNOyUdKdnCpQh8kTCPipQ2REHdo5yKQOQR1aMScmkASDmCMTSAt/c/kVKn1grb463vNvNu6BSYCJdJcvaWfPUG3ZsA4f4AsbMqUO7XpwPT2/qENQh9QhYKs6JMQEkoQgE5kqa9RY3bz6v79qt+PqCXTWc4aQQR8YH7BhHY7RmSFzQEbU4eKaFtu93wMBP3WIjKrDQMBv1zpcx+kBdWhFiAkkEUEmMtgDNuwF9oCYawjUIXUInP/3vKhDgDoM8xinBdRhJEJMIMl6gszjtAQyTJbOrHJqJws5LcjAOiyx2THdzGlBptXh4pqWm6lDILl1GAj4uR4CKVCHhJiAPVxJEyADjbHZ8YzmlCADee1yID29QqlDUIdJ1DOElTpEJiqxWR3SGxrUYRSEmEDyv7R5aQXwpS3pdVjC6UCGGsP/CQBs+n8CQB0CsCDEBJLvMpoAvPcB8EUJAAAA6BshJgAAAAAAAABbI8QEAAAAAAAAYGuEmAAAAAAAAABsjRATAAAAAAAAgK0RYgIAAAAAAACwNUJMAAAAAAAAALZGiAkAAAAAAADA1r5CEwDAub0w323cHlc0Rzfc/3RMzwHUCQDq6vx555mH1Naw1bi/qLqZRgEAIE0QYgIAXxQBAAAAwLby8ydHPOZ2u/WLX/x8UNuWl5dpzZonadgUw3ByAAAAAAAApJTm5maFQqF+XxMIBGioNEKICQAAAAAAgJTj9x/s9/nDhz+kkdIIw8kBoMfMRauM2xc5htMgAAAAAGBjra2tKiub1efze/fupZHSCD0xAaCHu9Rn/MstmE2DAAAAAIDNFBQUGLcbGt7v97W1tXVRt0NqIsQEAAAAAABASrj22muM2/3Ni9ne3m7cLigoUFbWpTReimM4OYCU8PqyefrkSJMkyZHt0m3PvRvxmuYdNdr1wsqYXzNi7ETdumaT8RyrkwPx1dUZ0ocNW/SHQKM6Ag1G3Y0rmiP3jf+kCy8efs5t2xq2Wmp/QvFNumpqiZwTvDQwksZ8vZi5aJXcpT61N25Tyzub1BFoiHoNSeR7erD7/vKL0+rw79KJQ7/RZ8GPjDrtrdUrvTP73T7U6tfh+l/pT4cPWn7u6KnXa9SkbyrHOzNqnQ+1LU52tOnDXW/puH+XsX2Op0hjry3TXz8/xRsU9rgGdnWptrZOe/futfQEKy8v0/Tp0zVv3q19bmteSXnlykc1b96tCgQCeuutLaqvr1cwGJLL5VRxcbEWLPiOcnNzaXBklM8//9xy3+8/GHVI+YEDfuP2pEkTVVn54jnrdvfuBv32t7/V8eMdamxsNJ5zu90qKirUddcVy+PxGI9/97v3WV63fXutnE5n1P2bX1tQUKDnn9/AyRwgQkwAKeFK70zji0pXZ1BdnSE5sq0XhxOH9pi+IJ37NVd6Z9KwQIIEW/brjUe+o67OoOXxT4406ZMjTWpr2KqypRsialSS2hu3qfGVpyK27eoM6sDmCh3YXKFrbv++8r99Nw0NW/hN1Xod2FzR5/OJfE8PZd9tDduMP+yF663VA5srVLpkbcQ0K+Y/Cob/3KbtVWraXqWbnqiKCCSH2hbtjdu0Y92DEY93BBosISyQTO3t7Vq+/BE1NzdHPFdbW6fa2jrV1PxSP/rRE+cMIE+cOKFlyx62BKGSFAyGVF1do/r6ej333AaCTGSUUaNGye12GzXW17yYLS0txu0JEyacc7+1tXVaterxqM81NzerublZlZUv6qmn1hg/78YbSy0h5u7dDVH/SNHV1WV5nbk3KWJHiAkgJQy/4muW+6c7/xgRfgRb9lvun+w43O9rwveJ8+5/LK5pKbHJsdCtL87CA4poAcme156K6K0WavVHDSjCffDaj5U9+u+Ukz+Dxh6ay6jDodm/aUO/7/dEvqfPV73sWPegbpswxbimhlr9fYafiTzejoO7Y9oeSKZQKKR7771PwWCo39c1Nzfr3nvv0+uvb5LD4ejzdefqORYMhvTrX2/V97737zQ+Mso3vnG1EWI2NLwftQbq6+vPfsjw5sftZy9dukxeb76cTqcmT7Z+fDEHp2YHD1pXUZ8yZTIncRAIMQGkBFfeFMv9P3902NK742RHW8SXyM5jv7d8Afryi9OW14TvE+f/tEp6l2ZIT45slwr+ZallOGl4D6y2hq26evYdllreV/2sZR/Xffdxo447Du7W1tX/ajy/9+frCDGHLp86HJre93PvcGZJusgx/Ly8p4e677+9anzU3pKhVr/2VT9r6dn40YF6uUt9kqTD9b+y/NzSJess+wi1+hVs2acL/+aSuB7v3p+vs9yfuWiVxhXNNv6PCbX61fDi48bIDSAZ1q5dZwkwV658VOXlZXI4HAqFQqqsfFHV1TWSzgSQP/vZS+cMIMvLy/Stb31LI0e6ztTg4Q8tvcW2bNlCiImMk5eXZ9zunRfTPIy7vb3dqEWXy9nnEG+z8eO/rldffdkyXFySAoGANmx4PmqPy9zcXEuv0OrqGq1YsTzymr3vbGcal8sZ8TMQGxb2AZASLs8ZZ7nfedQ6POfk8daIbcK/xJw8/mG/+wQQP668KcotmG2ZDy+3YLYK/mWp5XXBln1na7SjzRKaTJl3nyXEyMmfoWtu/76lxk92tNHYSKoRYyfKt3aL5jxSKXepT+5SnzH0OpHv6Xjs2znBG3X+SecErwoW/i/LY+bpWI7tO5t7Xz379oh9OCd4lf/tuy3X2aEeb8fB3Zbreu9cpOb/Y5wTvMoaNYY3JZKmvb3dMuz7nnvu1rx5txo9LZ1Op1asWG5ZIbmy8kV1dXX1uc/y8jKtWfOkyspmyePxyOPxaN68Wy37OFevTyAdhfeA9PutPR3N82EWFxfHtM/eGov2+NKl37c8tnfvXkudmr3/fuSK6eZV1OfOncsJHCR6YgJIGeOK5qitYask6U+HrRepzz8+EfH6toatlqGqf/7osGVfAM6/nLC5aM2hRPiUEFdNjvzA6cqbarkfbNnPHySQVFmjxvT5HkzkezrR9dLf6841XUQijrfz2O/PuX2qCv3+gHfYMPdjdjiWe+65eww9+gavvn6X5f78+b6or7vllpsjenRFm8+v3/97WGU5rt5///2S/PzJ1GEKyc3NlcvlNEL88HkxzcO6zb02h/Lz+lJcPFPr1q037re2HlZhYeHZ/+dDIcscubHMz4noCDEBpIxRk641QsxPjjTpyy9OGz0w/hA480FwxNiJlmAk1Oo3eoiYe2+OmnQtDQokwYUXD1eOp8jokWUONsw9vUaMnRh10Z/wHl9f/uUzGhW2lcj3dDLrZcTYicZ19nfbXtNVU0rOGY4O9XjNf/BwZLuibp+qPgsd90q6yQ7HcuzYMQp3CMwhRX/DV8eP/7rl/unTp2m8pL/3P7pO0nXUYWopLi42pmcInxfTPB9meK/NeAsPVGtr67Rw4Z3G8+G9RGfMKOLkDRLDyQGkjL+9arzlvnl4eG8g8tXx+ZZVx829L829Ny+5YiQNCiTJRZdkGbfNPbrMgWasQ0KZ+w52lsj3dCL3fbKjTaFWf5/Pm6+zXZ1B1Tw4V7srV6nj4O6EHa95e+a0hl35/WfrxuvtOzQJ79FlHpYKIHbR5sWUrPNhut3ufntRxqK9vV2BQKDf15iHiJuPRTrTS7RXQUFBv4t5oX/0xASQMi6/0vpX697FfcxftLLHuC2vOf3xHySdWdTH/GXoqxNYjBqwm/BA851nHqJRwHv6POy7vXGbOo/+Xh+3/c4yb2Vfvj7zH9Ra/6blGJq2V6lpe5Uc2S5NmXefsQhQvI53MEPYU4Urb0qtpF/Y4VhKSkq8ktZRvYPD3JSp65prpr8saSN1mFqizYtZVjbLMh9mUVHhgPdbV7ddra2tOnSoyTL1Q3+mTp2iysoXjfu9C/9I1vkwb7yxlBM3BISYAFJG+DDU3uHh5t6W4b01j/t36ZsLHrD02hwxdqJlIQAA9tPVGTSmjwB4Tydm3yc72vTufy4dcI/my3PG6brvPq73nn80Ilzs6gxq1wsrdWRPneY8Ukl9x+CSr+YEu7u7d9rhWAIBPycEGSk3N/codZiS580yjPuPf/yjJOnEibPrJQxk/sn29nYtX/6IZWqIWBUWFlqOpXdOzvb2dsv+Ej20Pd0xnBxASrli3NXG7d7h4ea5LsNXWu2dO9McdF4ZtrAIAACZpqszpK2r77EEmBNnLdDMRatUumStbnqiqt/tc/JnyLf2Lc1ctMqYj9qsI9Cg5h01NDQAIKHMK4/v2fOBJGvPR683P6b9hEIh3XvvfZbAcf58n1aufFRPPbVGr7768oCOpXeuTnOv0HgMbc909MQEkFKyx/ydcbv3i1dvmGlecdy8kvnJ4x8aw8olafgVX6Mh7eFohS9vjB0OZHFNS4mkdzkl51+08KO3hm+4/2kaKPHeq/DllVCHiZfI9/Rg9t20vcrSi3LOiv9STv6MAe3jwouHy13qk7vUp1CrX/uqn7UMRz9xaE/EsHLqG4h06aWsNA4MlnlezMbGRnV1dRlBpNvt7nOBrXDV1TWWKSGee+6nlhXGYzFt2jQjvJSkQCBgWSV9MEPbYUVPTAAp5fIrrcMBOg7uNsJM84rj5tt//uiwPvvTceM+CwIAyWUeRmpe4CPHc3alxlMnjtJQSHmJfE8Pdd/H/bss+xpogBnOOcGr0ofWy5HtilrrQz1e8x88zIv8AHZSXl5m3DYv8hOuvb3dct8cwgAYmPDh2bW1dcbtgYSG5t6bBQUFAw4wpchVxw8f/tCySvrUqXwPHSpCTAAp5fKccZYvSEd/838Zt83zYZpXHz9xaI/li9TlOeNoSCBJTna0We6b/+Bgni7ikyNN6upkgQSktkS+p4e6b/Mw8osuyYrLMV148fA+/1A41OM1/8GjqzPI/w+wpZycHON2MBiyrE5sdvjwh5b7I0e6aDxgkHJzc+V2n13ctabml8btgcyHaR5GnpU1uN7RDodD8+f7LMdi7t2Zn5/PCRsiQkwAKWf01OuN203bz87ZZV693Lz6uDnANA85B3D+Har9Py33zYHHyInTLM8d2FxBgyGlJfI9Hc99x7OXqHlf5t6TQz1e8x88JOmjA/W8wWA74b2szMNKzV56aePZ66DLOageXwDOMve4NIeRsc6HGe7YsY8GfSzTpk2Leizz5/vkcDg4WUNEiAkg5WSPcUc8luMpsqw43ruS+bm+BAFIjL9+fkpffnHauP/lF6f1m6r1lj88jCuaY+kZnZM/wxJ6NG2v0u7KVRG9N7s6Q2pv3KZ3nnlIoVZW8IR9JfI9PdR9m6+RnxxpUnvjNst2/R3HO888pPbGbZbekF9+cVrNO2osPTzNC+kN9Xivmlxsed2uF1aqeUeN8f9M789nqDmSqbCw0NIjrLLyRW3a9Lq6urrO1FUopNWrf2QJNhYtWkTDAUMUrcflQObDlM4MIe/V3NysurrtlucDgUBM++krOGXaiPhgYR8AKcc8bLzX1zwFEY9dMe5qywIDknWYOYDE6Qg0aOOd3+zzeUe2S9fevjTi8aK7H9Wbjyww7jdtr7IEn+Gunn0HjQ1bS+R7eij7zrthnuUauWPdg8p5Z5MuuiRLf/38VMT106ytYatllENfJs5aELfjdWQ7dc3t39cHr/3YeGzXCyu164WVvMlgK8uXP6w77rjTuL9q1eNaterxqK8tKCjQvHm30mjAEEULDge6iM4tt9ysxsZG4/7Spcu0efMbysq6VKdOfWZ5rj9Op1MFBQURrw+fLxODQ09MACnHOcEb8Vj26L+LfGxM5GNfjbItgPNrxNiJmrOiUo5sZ9T6vumJKsvct/3tZ3g2f5iA/a9ZiXpPD2XfuQWzI6ZY6Qg0qK1hqzoCDXJkuwY9BYsj26XSJWsjanyobeG+8Z+ijrIw/1ymjUGyeTwePfXUGrlc/fcAKy8v09NP/wcNBsTjWut0WnpBSwObD1OSyspmWRbnks6sdl5bW6fGxka5XM6I5/ty442l1uvXAHuFom/0xASQknI8RZZeIpfnjI/y5W5KxBci85BzAPF123M79dGBep3++A/67E/HLT21HNkuufKmaNSkazWuaHa/teic4JVv7Vtqa9gWsTDXiLET9dXx+Ro16ZvKLZhNoyM1vlwl8D09lH3fcP/TGjXpWh3ZU2dcU0eMnahxRXPkvvGf1NawLWqPS9/aLfpo/059cqQpYgXyK8ZdrYmzFkT9I8VQj/fCi4drziOVam/cppZ3NlmO+UrvTE2ctUCnO/8YUy9RIJHKymZpxowi1dT8Unv2fGD0yHK5nCouLta0adNUVjaLhgLiqKiocMjzYa5Z86SmT5+ut9/eYdSt2+1WeXmZfL5/VG1tnWX1876E97qMNfzEuQ3r7u6mFZLR8MOG9Tb8e93d3SW0SOZaXNNSIuldWgIZ6L0KX14JdQhQh9QhMtwPK3x5j9nhQAIBP3WIjK1Dj8dLHSJO5zBgmVbiued+ygJecapDhpMDAAAAAAAAcbB//wHjtsvlJMCMI0JMAAAAAAAAYIi6urpUVXV20bq5c+fSKHFEiAkAAAAAAAAMQVdXl372s5cUDIaMx6ZOnULDxBEL+wAAAAAAAACDkJ8/Oerj5eVlDCWPM3piAgAAAAAAAHHicjm1ePEiGiLOCDEBAAAAAACAQZg/32fcdrmcuueeu/XKKy8rNzeXxokzhpMDAAAAAAAAg7BixXKtWLGchjgP6IkJAAAAAAAAwNYIMQEAAAAAAADYGiEmkHx+mgAZ6ijHAiTdThsdy6ecDgAAAPSFEBNIsgpfHl/akKmO2qgOj3I6kKE+tVEd8kc9UIdJ5vF4d3I6QB1Sh4Bdvx8SYgL28CZNgAz0BnUIJN1O6hBIOrsttnqQUwI+l1KHgB0/lxJiAvawniZAhnnPhr2u3uC0gDqkDoEk+I/FNS0L+VwKJO966PF4j/L9ELB/HRJiAjZQ4cvbKek9WgIZ5DEb1uFG6hDUIXUIJMlLdgkyPR7vRtELDJnlAbsdEHUI6jA6QkzAPm6WdIpmQAb4YU9wb0cLqUNQh9QhkCQv2ahHJp9LkSnu8ni8dp2TmeshqMMwhJiATfQs8FMi/uKG9PbDCl/eYzauw6PUITLAkhSpw2OcKmQgWwSZPUP6qEOku7t6ejzaUk+oQx2COjQhxATs9cWt90L1Q/FXN6SX9yRdb+fghDpEBtXh+hSpQy91iAxllyCTOkQ6Xw8n2znAjFKHz1CHoA6lYd3d3TRdEgwbNqy34d/r7u4uoUUQzeKalpt7LlpAqvpU0hs9PauoQ4A6HEwNXqYzf1igDpHqdfgVSf8xgG3u6pknNukCAT91iLS5HtpwER/qEJnkqKSdg61DQswkIcQEAAAAMktPD8uXBrCJbYJMAACSjeHkAAAAAHAe9ASSdw1gEzst9gMAQFIRYgIAAADAeUKQCQDA4BBiAgAAAMB5RJAJAMDAEWICAAAAwHlGkAkAwMAQYgIAAABAEhBkAgAQO0JMAAAAAEgSgkwAAGJDiAkAAAAASUSQCQDAuRFiAgAAAECSEWQCANA/QkwAAAAAsAGCTAAA+kaICQAAAAA20RNkLhnAJgSZAICMQIgJAAAAADZS4ctbL+nlAWxCkAkASHuEmAAAAABgMxW+vIUiyAQAwECICQAAAAA2NMggs4SWAwCkI0JMAAAAALCpQQSZbyyuafHScgCAdEOICQAAAAA2NsAgM0vSToJMAEC6IcQEAAAAAJsjyAQAZDpCTAAAAABIAQSZAIBMRogJAAAAACmCIBMAkKkIMQEAAAAghRBkAgAyESEmAAAAAKQYgkwAQKYhxAQAAACAFESQCQDIJISYAAAAAJCiCDIBAJmCEBMAAAAAUhhBJgAgExBiAgAAAECKI8gEAKQ7QkwAAAAASAMEmQCAdEaICQAAAABpgiATAJCuCDEBAAAAII0QZAIA0hEhJgAAAACkGYJMAEC6IcQEAAAAgDREkAkASCeEmAAAAACQpggyAQDpghATAAAAANIYQSYAIB0QYgIAAABAmiPIBACkOkJMAAAAAMgABJkAgFQ2rLu7m1ZIRsMPG9bb8O91d3eX0CLoSyDg90q6jJZAivJ7PN5PqUOAOgRgH4trWjZKujPGl5+SVFLhy/P3BJpcD5Gy18MKX96naVC/1CFSVoUvb+dQtifETBJCTPQnEPCPkfSYpJt15q/gQCo7KGm9x+PdSB0C1CEAexhgkPllz7/htBzS4XpY4cvbmGL1WiJp4QBqFkjLOiTETBJCTPQlEPCvl3Q/LYE0dEzSzR6P108dAkn90LgwFeoQQOINMMgE0u56WOHL86dAnfK5FNRhD0LMJCHERDSBgJ8Pkkh3pySV2DlAoQ5BHQLIJASZyPTroZ2DzMU1LX5J+ZwqUIdnsLAPYBOBgP8xPkAiA2RJ2hkI+C+jDgHqEEDyDXCxHyDdrodvLK5pseX1sKcHJgEmqEMTQkzABnrm3vsBLYEMulCtpw4B6hCAPRBkIoON1pk50G2lZw5MhpAjk+rwgVheSIgJ2MNjNAEyzJ09oSF1CCS3DumNCUASQSYy2kIb9sZcyGlBhnkgljokxATsoYQmAO/7pLuZU4IMxPsegKEnyPySlkCGyeJzKZAadUiICdjDaJoAGWiMXQ6kpzdaFqcE1CGATLa4pmWMpAtpCWQgr43q0MvnUlCH0RFiAkkWCPhLaAVkKDu9972cDmSoMTQBAP5PAGyFqV6APhBiAgAAZK4xNAEAAABSASEmAAAAAAAAAFsjxAQAAAAAAABga4SYAAAAAAAAAGyNEBMAAAAAAACArRFiAgAAAAAAALA1QkwAAAAAAAAAtkaICQAAAAAAAMDWvkITALCL/PzJxu3y8jKtWfMkjQJQfwAAAEhxL8x3G7fHFc3RDfc/TaNgwAgxAQAAAABIEMIbAIgPQkwAAAAAAAAM2MmONn35l8+N+84JXn5PJAwhJgAAAAAAAAZs/6YNamvYatxfVN3M74mEIcQEAAAAACBBZi5aZdy+yDGcBgGAQSLEBAAAAAAgQdylPhoBAOLgApoAAAAAAAAAgJ3RExOArQUCAb311hbV19crGAzJ5XKquLhYCxZ8R7m5uRGv7+rq0u7dDfrtb3+r48c71NjYaDzndrtVVFSo664rlsfjMR7/znf+Wc3NZ+c0ef/93XI4HFGPZ9myh1VbW2fs7xe/+Lnl+VAopG3balVbW2fs0+Vyau7cuRE/F7Cz3vfynj0fGHXkdrtVXl4mn+8f+6yReNTCYLfNz59s3F658lHNm3frgP8PAQAg3vpbndz83MxFq+Qu9SnU6tfh+l/p2L531dUZlCPbpdFTr9ek8tt0ec44GhS28M4zD1nmiOzvPd3nZ75Bvte7OkP6sGGL2hq26pMjTZIkR7ZLE4pv0lVTS/pcdOfLL06rw79LJw79Rp8FP1JHoMF4bsTYibrSOzNi+6H8noM9zmj7bm/cppZ3Nqkj0BDx/0hvO/7p8EHLzxk99XqNmvRN5Xhn6sKL039OBz4AAA4HSURBVGMqC0JMALZ06tRnlsCwVzAYUnV1jerr6/XccxsiQoja2jqtWvV41H02NzerublZlZUv6qmn1qisbJYkqby8zBJiHjx4UIWFhVH3YT6e8vIyy3N1ddu1du1aBYOhiGOurHxRlZUvasmSB7Rw4Z2cYNia3+/Xv/zLnRHv5d4aqq2t0zPPrJPT6Yy6/VBqIV51dOLEiUH9HwIAQLKc/vgPUQOTrs6gmrZX6di+dzVnRSVBJlLeXz8/Nej3envjNjW+8pS6OoMR2x7YXKEDmyt0ze3fV/63747Ytq1hm3a9sDLqMX1ypEmfHGnSgc0VKl2yVrkFs4f0Ow7lOMP9pmq9DmyuiP4dd0dN1N+pty2btlfppieq0mY1dUJMALZk7kEZTTAY0q9/vVXf+96/D2r/S5cuk9ebL6fTqSlTJluea209HDXEDAQClvvm7QKBgJYuXXbOn7tu3XpNmDC+z5AUsIPwADHiw1Jzs9auXac1a56MWieDrYV41lFl5YsJ/T8EAIB46yukMIcSH+56S99c8ACNFX8li2taHrPJsYxJ98Y294AcyHs91OrXjnUPnnP/H7z2Y2WP/jvl5M8Y1PHtWPegbpswRY5s56C2j+dx7t+0ISIINf+cvkLZdEWICcC2ysvL9K1vfUsjR7okSYcPf2jpZblly5aIAGL8+K/r1VdfjhhuGggEtGHD85ZwdPfuBs2bd6s8Ho9cLqcR3NTW1kXt5bV//wHjtsvltPyMDRuetzz3gx+sNAKW999/X/fe+2/G8z/5ybOEmLA1l8upBx98UDNmFBnDxsN7SNbW1um22/45otaGUgvxrqPB/B8CAEAyjSuao7HTS+XIHilJ+vNHhy0hRWv9m4SYiXFdzz/E6Ib7n9YN9z8d0aNyUXVzwt7r+6qfNW47sl267ruPGwFgx8Hd2rr6X43n9/58XUQ4+LdXjY/aKzHU6te+6mct4epHB+rlLvUN6vcc6nGa9QaYOZ4ijb32zEjAixxnhoYfrv+V5eeULlln+d1CrX4FW/bpwr+5JG3edyzsA8CWysvLtGbNkyormyWPxyOPx6N5825VQUGB8ZpovcV6Xxvt8aVLv295bO/evcbt4uJi43Zzc7NCoch979nzQdTXt7e3W8LRRYsWWcKVwsJCLVnygGX/7e3tnGTYltfrVVnZLMu8l2Vls/Tgg9a/KJuD/aHWQrzraLD/hwAAkCy989zlFsyWc4JXzgleuUt9yvEURQQaQKa91092tFlCxinz7rOEfzn5M3TN7We/731ypEknO9os++j9WeGcE7wqWPi/LI+dOLRnUL9bPI7TbMTYifKt3aI5j1TKXeqTu9RnDHU/tu9d43VXz7494ndzTvAq/9t3p9UUFPTETL78YcOG7aQZMtfXvva1y7Zu3UJDxCgr69JBb9vf3HfTpk1TdXWNcd/vP2jMmSmdWTDIHLBMmzbNuH3ggN+yrxkziiL2Hz5k/cABf8bPxffmm79y5edP3kkdpo7w97Z5Ltmh1sL5qqOh/B8CAEAyXHRJFo2AjH+vB1v2W+5fNbk44jWuvKkR28Qa4MUr6Iv3cWaNGtPnc5n4Rw1CzOS7THRbz2h/+MMfaAQbCA9MWltbLSHmwYMHLc97vfnGbXOPTrfbHXWxk/DeoZ9//nnGt/kf//jH/2GX//+ow9g4HA4VFBQYgb7fbw0eh1IL1BEAAAD6Yu4ZOWLsxKjzVYb3RPzyL5+l9XGOGDvRWI38d9te01VTStJ+4S+GkwPICO3t7REL85j1hjO9Ghretzzf2nrYuF1QUGAJWMxBzujRV8V0POE92IBUYe7JGD4ceyi1QB0BAACgL+YejlmjxsS0TW/Ady4nO9oUavXb/jjDXemdadzu6gyq5sG52l25Sh0Hd6ft+4CemEnS3d09jFaAJAUC/hJJ79IS8VVXt12tra06dKjpnCud97rxxlLjtb3zYvaGleb5MK+99hrrhcoU5Pj9fi1b9jAnIAbf/e7ioxs2PDeGOkyjD5dDqAXqCAAAAH0xD50OtuzXO888NOh9tTduU+fR3+vjtt+dc6X0ZB7nuXx95j+otf5Ny89s2l6lpu1VcmS7NGXefXKX+tLqfUCICSCttLe3a/nyRwbVQ2vyZGu3/t7Vy8Pnwwyfl88sGAyptraOE4GMN5RaoI4AAADQl67OoGWl8Fid7GjTu/+5dNA9H8/Xccbq8pxxuu67j+u95x+NmB+zqzOoXS+s1JE9dZrzSGXanHtCTABpIxQK6d5777P06Jo/36e8vDwNHz5cI0e6dMcdd/a5fW5urlwup7F9S0uLpDNhZi+Xyxl19XMAAAAAKeuYpKM2OZbLJOVzSuKrqzOkravvsYR9E2ctUPYYty5yDJcje6TefGRByv1eOfkz5Fv7ltoatqn57V9EBLQdgQY176hJmx6ZhJgA0kZ1dY0lwHzuuZ+qsLBwQPuYO3euKitflCTV19drxYrlam1tNZ4vLi7ud/vy8jKtWfMkJwMZwe12J6QWqCMAAHCebazw5T1mhwNZXNNSIqY56te4ojm64f6nB7RN0/YqS4A5Z8V/KSd/hu2OczAuvHi43KU+uUt9CrX6ta/6Wcsw+ROH9qRNiMnCPgDShnkxnoKCggEHmJI0deoU43YwGFIoFNKhQ2f/mjVt2rSIbcwLAh079hEnAmnNPMw7fAGeodQCdQQAAIC+5HiKjNunThwd8PbH/bss+0pUgDnU4xwq5wSvSh9aL0e2y3gskUPazzdCTABpwzwPpnkF5YHIz7eO3Ni9u8EyH+aMGUUR20yaNNFyDKFQiJOBtNTe3m65P3369LjVAnUEAACAvlwx7mrj9idHmtTVObDPiuZh1hddkmXb44yHCy8eLlfe/9/e/YU2dYZxHP95Mxlx86LdEsXB2jLXRD2G4crabtChNqkIa9nCcDIQduHltIKKMHBDx7yYf3BMCrtQvIg0UysbNomV1WGIeLF1gbUiVGWUsoKyxhlk3nQXLVle067VRHJyzvdzlfScJOe853140yfPe943HNkPSGICcKSnreTyeDwKh0P557HY9/nHzc3N8ng8Ra8prN6UlJ+ODjhNNHrGeP74YlilxAJxBAAAgLksC5gz4n493/PU7/UsKyTLeZylKDzH2rqAY/oBSUwAjlE4HXVkZESJRNLYnslkFvQ+hdVlhdWdGzdumHX/lpYW496Avb0xHTz4ZVHV2sTEhBKJpPbs2bvgYwEq8qUne1+5XC7/PJfL6fjxb9TbG8v/LRwOqb6+vmyxQBwBAABUn8Ues6rxVro///jRwwdl+5wVa982knHDyaiufveF/hobNfbL3ZvQrXS/Lh/bpYmbQ/+9vmCa993bw8ZxSjL2LeU8Sz3OJ3H52C7dSvcb1Z6PHj7QyEDMqDx9JfiOY/obC/sAcIyurk5j6vfu3Xt0/nyfli59UdnsfWPb/5ltyrhUXHVWaN++vcbK5729MSPh87itWz/igsG20um0Wlrmvk+Qz+dVd/fOsscCcQQAAFBdal41F3ocONItHemWVP6FbVo/+cxYQXw4GdVwMjrn/qs7Ps4/blz/vrHYzcCRbq24fFaLX1iqf/7OGttKPc9SjvNJjKYuLuh+l4H2LY7pb1RiAnCMUKjdmAouTSdj4vGE0um0fD5v0fbZeL3eolWXfT5vUdVZIcuydPr0Kfl83nnf3+/3y+v1csFQlfx+v06c+HbOPlxKLBBHAAAA1aWhtcNYROZZ8q4M6r0D0QV9Xm1dQEtqluWf1zd3qKF1k7HPWCal0dRFjWVS8tT4irY/7XmWcpzl5KnxacPOw/LUOOc7M5WYABzl0KGv1NTUpEuXBvKVl36/X+FwSJHIB4rHE8bqynMJh0PGVPLNmzfP+xrLsnTu3FnF4wldv37d+By/3681a1Zr3bp1CoXauVCwnWQyrqtXUxofH9fY2JjRf30+r4LBoJqamhQOh2a9N2y5YoE4AgAAqB7PPb9EnQfOaDgZ1c2fLyh3709J09WJr7d1lf3zvCuDihz+QaOpfo3/fs2oRKytC+jl19Zq+ao3Vd/cUfTa9Z9+reWr3tLta4l85WVtXUANrZvk3/ihRlP9c1Y2Pul5lnKcCxU5/KP++GVQd28PG++/wmrVSw2rFWjf4qgEpiQtmpqaIuqACspkhtok/URLwIWuWFawjTgEiEMA9rA9doPxEG71eU+kcT9xCNg7DplODgAAAAAAAMDWSGICAAAAAAAAsDWSmAAAAAAAAABsjSQmAAAAAAAAAFsjiQkAAAAAAADA1khiAgAAAAAAALA1kpgAAAAAAAAAbI0kJgAAAAAAAABbI4kJAADgXpM0AQAAAKoBSUyg8oZoAtD3K+4OlwPEIQDwwwYAwL5IYgIVZlnBSUlZWgIudMdGcXiHOIRLkbAAkNcTaeSHDfC9tPJxOMjlgEvNOwaRxATsoY8mAP2e4wHo9wBs4AJNAMZD4hCogMH5diCJCdjDSZoALnNlpvqROAQq+A+SDeMQQOUdpQngMqd6Io2TxCFg/zgkiQnYgGUFByUdoyXgEllJ22wah/zqDTfF4Q6aAcDjZqayMh7CTePhfuIQqI44JIkJ2Md+Sb/RDHCBHTau/tpGHII4BADGQ7inr/dEGvleClRW50LjkCQmYBMzC/y0iV/c4FxZSV2WFTxJHALEIQD7mpnS1ybpCq0BB4+H7/ZEGvuIQ6DicTi40BcsmpqaotkAm8lkhjo1XZm5ltaAQwanPk1Xfk1WURxu0/R0W+IQxCEA19oeu8F4CKeNh0clHbXhfTCJQxCH8/gXb5Uc1wUvyPQAAAAASUVORK5CYII=)\n",
        "\n",
        "As beam search expects token sequences with probabilities, We first need to convert the output activations (logits) to token probabilities. We then take the log of these probabilities into so-called logprob values (so as to prevent computational underflow problems with extremely low probability values).\n",
        "\n",
        "The following code implements the conversion of logits to logprobs and the computation of a logprob score of a full output sequence."
      ],
      "metadata": {
        "id": "RwgkGKJAL-xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def log_probs_from_logits(logits, labels):\n",
        "    logp = F.log_softmax(logits, dim=-1)\n",
        "    logp_label = torch.gather(logp, 1, labels.unsqueeze(1)).squeeze(-1)\n",
        "    return logp_label"
      ],
      "metadata": {
        "id": "phPav5TUpyKU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_logprob(model, labels, input_len, tokenizer, max_len=16):\n",
        "    with torch.no_grad():\n",
        "        seq_log_prob = 0.0\n",
        "        input_ids = tokenizer(input_txt, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(\"cpu\")\n",
        "\n",
        "        for i in range(len(labels[0])):\n",
        "            # Pad the input tokens\n",
        "            tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "            padded_tokens = pad_prompt(tokens, max_len=max_len)\n",
        "\n",
        "            # Re-encode the padded tokens\n",
        "            encoded_input = tokenizer.encode(\" \".join(padded_tokens), return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_len, add_special_tokens=False)\n",
        "            input_ids = encoded_input[0].to(\"cpu\")\n",
        "\n",
        "            output = model(input_ids)\n",
        "            next_token_logits = output.logits[0, :]\n",
        "\n",
        "            # Get the actual next token id from labels\n",
        "            next_token_id = labels[0][i].unsqueeze(0)\n",
        "\n",
        "            # Calculate log probability of the actual next token\n",
        "            # Added squeeze(0) to next_token_id to make it have shape [1]\n",
        "            log_probs = log_probs_from_logits(next_token_logits.unsqueeze(0), next_token_id.squeeze(0).unsqueeze(0))\n",
        "\n",
        "            # Check if the log probability is -inf and skip if it is, log a warning\n",
        "            if np.isinf(log_probs.cpu().numpy()):\n",
        "                log(f\"Warning: log probability is -inf for token index: {i}, skipping.\", level = 3)\n",
        "\n",
        "            else:\n",
        "                # Add to the sequence log prob\n",
        "                seq_log_prob += log_probs.cpu().numpy()\n",
        "\n",
        "            # Prepare for the next iteration, if it's not the last token\n",
        "            if i < len(labels[0]) - 1:\n",
        "              input_ids = torch.cat((input_ids[1:].unsqueeze(0), next_token_id.unsqueeze(0)), dim=1)\n",
        "\n",
        "    return seq_log_prob"
      ],
      "metadata": {
        "id": "Os_kq8-Ip2TK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running our greedy generation again, we see that the logprob of the repetitive output sequence is about -183. We are going to use this score to see if alternative strategies, like beam search, may lead to better scores, which means higher (less negative) logprob scores."
      ],
      "metadata": {
        "id": "1HlMQ2q6NUQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]), tokenizer=tokenizer)\n",
        "print(tokenizer.decode(output_greedy[0]))\n",
        "print(f\"\\nlog-prob: {logp[0]:.2f}\")"
      ],
      "metadata": {
        "id": "UIa50vobp4Lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c51905e-f31c-4fd8-cc72-54707e2ee5a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The wave of new import taxes is expected to cost American consumers and businesses hundreds of billions of dollars, radically altering the economic outlook. Businesses are being affected as countries around the world impose restrictions on movement, reducing economic activity. Unemployment is on the rise, and spending continues to decrease in both individuals and businesses. This has caused a global recession, with some countries faring worse than others. In addition, many countries have put stimulus packages in place to help mitigate the effects of the pandemic, but the end result is still uncertain, the region overall is expected to experience a strong recovery in the coming year. 1. Plant - based eating : Plant - based eating is becoming more popular every year and will continue to trend in 2021.\n",
            "\n",
            "log-prob: -183.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the beam search strategy with 5 beams produces an output with a less negative logprob score. It does take longer to generate than the greedy strategy; it involves generating multiple sequences in parallel."
      ],
      "metadata": {
        "id": "cFpR5MnuNwEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_beam = model.custom_generate(**tokenized, max_new_tokens=max_length, do_sample=False, num_beams=5)\n",
        "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]), tokenizer=tokenizer)\n",
        "print(tokenizer.decode(output_beam[0]))\n",
        "print(f\"\\nlog-prob: {logp[0]:.2f}\")"
      ],
      "metadata": {
        "id": "r5llYYwIp7M3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "6469cda1-c627-44e0-a521-731e03f82a7b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7134101dc63d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_beam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_logprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_beam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nlog-prob: {logp[0]:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-55a3ad8de9d6>\u001b[0m in \u001b[0;36mcustom_generate\u001b[0;34m(self, input_ids, max_new_tokens, num_beams, do_sample, temperature, top_k, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0;31m# Get model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimbl_input_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-55a3ad8de9d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Distance: {distance}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Convert Timbl output to Hugging Face format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_huggingface_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Logits: {logits}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-55a3ad8de9d6>\u001b[0m in \u001b[0;36mconvert_to_huggingface_logits\u001b[0;34m(self, distribution)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Filter out tokens not in the Hugging Face vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         hf_token_ids = [self.tokenizer.convert_tokens_to_ids(word) for word in distribution.keys() \n\u001b[0m\u001b[1;32m     65\u001b[0m                         if word in self.tokenizer.vocab] # Filter for valid tokens in vocabulary\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-55a3ad8de9d6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Filter out tokens not in the Hugging Face vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         hf_token_ids = [self.tokenizer.convert_tokens_to_ids(word) for word in distribution.keys() \n\u001b[0;32m---> 65\u001b[0;31m                         if word in self.tokenizer.vocab] # Filter for valid tokens in vocabulary\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Vectorized operation for probability assignment:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36mvocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36mget_vocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_added_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Temperature and Sampling\n",
        "\n",
        "**Temperature** (T) is a crucial hyperparameter in text generation that can warp the token probability distribution in two directions. By default, T=1. With colder temperatures, T << 1, probabilities are more extremely drawn towards the most likely tokens, and less likely tokens receive even lower probabilities. At higher temperatures, T >> 1, the probability distribution becomes flatter; tokens become increasingly likely. The function below generates a figure that illustrates this with T = 0.5, T = 1, and T = 2.\n",
        "\n",
        "Intuitively, lower temperatures lead to conservative next-word prediction, while higher temperatures lead to wildly unpredictable next tokens."
      ],
      "metadata": {
        "id": "suPX3KBrqD1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def softmax(logits, T=1):\n",
        "    e_x = np.exp(logits / T)\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "logits = np.exp(np.random.random(1000))\n",
        "sorted_logits = np.sort(logits)[::-1]\n",
        "x = np.arange(1000)\n",
        "\n",
        "for T in [0.5, 1.0, 2.0]:\n",
        "    plt.step(x, softmax(sorted_logits, T), label=f\"T={T}\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel(\"Sorted token probabilities\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZjSY498cqKLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know how temperature works, we introduce the next generation strategy: **sampling**: when choosing the next word, we sample from the predicted token distribution, weighted by the token probabilities. Chances are high that we choose a token with a high probability, but not necessary always the most likely token. Temperature, as explained, warps this probability space. Let's run the sampling strategy with a high temperature of 2."
      ],
      "metadata": {
        "id": "t2ywWGDzSZ2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_temp = model.custom_generate(**tokenized, max_new_tokens=max_length, do_sample=True,\n",
        "                             temperature=2.0, top_k=0)\n",
        "logp = sequence_logprob(model, output_temp, input_len=len(input_ids[0]), tokenizer=tokenizer)\n",
        "print(tokenizer.decode(output_temp[0]))\n",
        "print(f\"\\nlog-prob: {logp[0]:.2f}\")"
      ],
      "metadata": {
        "id": "_aaVeEmpqSlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is obviously gibberish, although the logprob score might not even be that low. Try some other values of T above 1 to see when the results start to be reasonably behaved. Generally, the first bits of text will be reasonable, but sooner or later things start to loose coherence.\n",
        "\n",
        "Let's run an example with T = 0.5. Try even lower values, above but close to 0, and check whether the results become more like the greedy strategy."
      ],
      "metadata": {
        "id": "e9H9hm2bTbaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_temp = model.custom_generate(**tokenized, max_new_tokens=max_length, do_sample=True,\n",
        "                             temperature=0.5, top_k=0)\n",
        "logp = sequence_logprob(model, output_temp, input_len=len(input_ids[0]), tokenizer=tokenizer)\n",
        "print(tokenizer.decode(output_temp[0]))\n",
        "print(f\"\\nlog-prob: {logp[0]:.2f}\")"
      ],
      "metadata": {
        "id": "EAdxroIQqXtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In combination with beam size it is possible to limit search with the **top_k** hyperparameter, which limits the top number of alternatives considered in beam search."
      ],
      "metadata": {
        "id": "Z5rDSeZocyeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_temp = model.custom_generate(**tokenized, max_new_tokens=max_length, do_sample=True,\n",
        "                             num_beams=10, temperature=0.5, top_k=3)\n",
        "logp = sequence_logprob(model, output_temp, input_len=len(input_ids[0]), tokenizer=tokenizer)\n",
        "print(tokenizer.decode(output_temp[0]))\n",
        "print(f\"\\nlog-prob: {logp[0]:.2f}\")"
      ],
      "metadata": {
        "id": "dw00I9-tdhob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}