{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antalvdb/mblm/blob/main/MBLM_graphics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MBLM Graphics"
      ],
      "metadata": {
        "id": "CZ2DUvDdGQgR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fV73kcnGP8M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# initialize data of lists.\n",
        "data = {'Model': ['IB1-IG',\n",
        "                  'TRIBL2', 'TRIBL2', 'TRIBL2', 'TRIBL2', 'TRIBL2',\n",
        "                  'IGTree', 'IGTree', 'IGTree', 'IGTree', 'IGTree',\n",
        "                  'GPT-2', 'GPT-2', 'GPT-2', 'GPT-2',\n",
        "                  'GPT-Neo', 'GPT-Neo'],\n",
        "        'Training set size': [51327,\n",
        "                              51327, 486655, 4890203, 100000000, 500000000,\n",
        "                              51327, 486655, 4890203, 100000000, 500000000,\n",
        "                              8892000000, 8892000000, 8892000000, 8892000000,\n",
        "                              196735500000, 196735500000],\n",
        "        'Token prediction accuracy': [0.0940576134962002,\n",
        "                                      0.101171766203795, 0.132626427406199, 0.170538733935463, 0.218024111725619, 0.246489617542861,\n",
        "                                      0.110462340349341, 0.137273703895277, 0.174762264751521, 0.22028408864839, 0.24814460448398,\n",
        "                                      0.311731587952094, 0.336613217681932, 0.349602116738948, 0.357832331993793,\n",
        "                                      0.362163291290335, 0.372329208610193],\n",
        "        'Tokens per second': [40.84,\n",
        "                              59.57, 42.5, 68.03, 118.21, 100.42,\n",
        "                              244.43, 318.71, 783.5, 739.04, 504.42,\n",
        "                              30.68, 10.72, 5.86, 3.43,\n",
        "                              3.9, 1.99],\n",
        "        'kWh usage': [0.381481,\n",
        "                      0.261655, 0.358419, 0.22401, 0.131488, 0.190552,\n",
        "                      0.063788, 0.048881, 0.019922, 0.021115, 0.038263,\n",
        "                      0.503662, 1.438911, 2.6263, 4.702076,\n",
        "                      3.941196, 7.780539]}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b20a6330"
      },
      "source": [
        "import altair as alt\n",
        "\n",
        "chart = alt.Chart(df).mark_line(point=True).encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y='Token prediction accuracy',\n",
        "    color='Model', # Add color encoding based on the 'Model' column\n",
        "    tooltip=['Model', 'Training set size', 'Token prediction accuracy']\n",
        ").properties(\n",
        "    #title='Token Prediction Accuracy vs. Training Set Size', # Add the title here\n",
        "    width=800,  # Adjust width to maintain 16:9 aspect ratio\n",
        "    height=450  # Adjust height to maintain 16:9 aspect ratio\n",
        ")\n",
        "\n",
        "chart = chart.interactive()\n",
        "\n",
        "chart.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a101889"
      },
      "source": [
        "# Task\n",
        "Generate a plot using the dataframe `df` with 'Training set size' on the x-axis (logarithmic scale) and 'Token prediction accuracy' on the y-axis. Plot a line connecting the two points for 'IB1-IG' and label this line in the legend. Add a line for 'GPT2' and label its four points as 'small', 'medium', 'large', and 'xl', with 'small' corresponding to the lowest 'Training set size' value. Set the aspect ratio of the plot to 16:9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85eda06b"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "### Subtask:\n",
        "Add a new column to the dataframe to store the labels for the GPT-2 model's data points.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2698eef7"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a new column in the dataframe to store the labels for the GPT-2 model based on the provided instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9465db89"
      },
      "source": [
        "gpt2_labels = []\n",
        "gpt2_count = 0\n",
        "gptneo_labels = []\n",
        "gptneo_count = 0\n",
        "for index, row in df.iterrows():\n",
        "    if row['Model'] == 'GPT-2':\n",
        "        if gpt2_count == 0:\n",
        "            gpt2_labels.append('small')\n",
        "        elif gpt2_count == 1:\n",
        "            gpt2_labels.append('medium')\n",
        "        elif gpt2_count == 2:\n",
        "            gpt2_labels.append('large')\n",
        "        elif gpt2_count == 3:\n",
        "            gpt2_labels.append('xl')\n",
        "        else:\n",
        "            gpt2_labels.append(None) # Should not happen based on the data\n",
        "        gpt2_count += 1\n",
        "        gptneo_labels.append(None)\n",
        "    elif row['Model'] == 'GPT-Neo':\n",
        "        if gptneo_count == 0:\n",
        "            gptneo_labels.append('1.3B')\n",
        "        elif gptneo_count == 1:\n",
        "            gptneo_labels.append('2.7B')\n",
        "        else:\n",
        "            gptneo_labels.append(None) # Should not happen based on the data\n",
        "        gptneo_count += 1\n",
        "        gpt2_labels.append(None)\n",
        "    else:\n",
        "        gpt2_labels.append(None)\n",
        "        gptneo_labels.append(None)\n",
        "\n",
        "\n",
        "df['GPT-2 Label'] = gpt2_labels\n",
        "df['GPT-Neo Label'] = gptneo_labels\n",
        "df['Combined Label'] = df['GPT-2 Label'].fillna(df['GPT-Neo Label'])\n",
        "\n",
        "\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "473f2a02"
      },
      "source": [
        "## Add labels to chart\n",
        "\n",
        "### Subtask:\n",
        "Modify the chart code to include a text layer that displays the labels for the GPT-2 data points.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02bafdfd"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a text layer for the chart to display the GPT-2 labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01b2c6e8"
      },
      "source": [
        "text = alt.Chart(df).mark_text(align='left', baseline='middle', dy=0, dx=5).encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y='Token prediction accuracy',\n",
        "    text='Combined Label',\n",
        "    tooltip=['Model', 'Training set size', 'Token prediction accuracy', 'GPT-2 Label', 'GPT-Neo Label']\n",
        ").transform_filter(\n",
        "    alt.FieldOneOfPredicate(field='Model', oneOf=['GPT-2', 'GPT-Neo'])\n",
        ")\n",
        "\n",
        "chart_with_text = chart + text\n",
        "\n",
        "chart_with_text.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "610e3240"
      },
      "source": [
        "## Compute and Display Regression Lines\n",
        "\n",
        "Now, compute the log-regression lines for the 'IGTree' and 'TRIBL2' models and add them to the chart with a separate legend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fb675a7"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "import altair as alt\n",
        "\n",
        "# Filter data for IGTree and TRIBL2 models\n",
        "igtree_df = df[df['Model'] == 'IGTree'].copy()\n",
        "tribl2_df = df[df['Model'] == 'TRIBL2'].copy()\n",
        "\n",
        "# Calculate log of Training set size for regression\n",
        "igtree_df['log_training_size'] = np.log(igtree_df['Training set size'])\n",
        "tribl2_df['log_training_size'] = np.log(tribl2_df['Training set size'])\n",
        "\n",
        "# Perform linear regression for IGTree\n",
        "slope_igtree, intercept_igtree, r_value_igtree, p_value_igtree, std_err_igtree = linregress(\n",
        "    igtree_df['log_training_size'], igtree_df['Token prediction accuracy']\n",
        ")\n",
        "\n",
        "# Print regression formula and values for IGTree\n",
        "print(f\"IGTree Regression:\")\n",
        "print(f\"  Formula: Token Prediction Accuracy = {intercept_igtree:.4f} + {slope_igtree:.4f} * log(Training set size)\")\n",
        "print(f\"  R-value: {r_value_igtree:.4f}\")\n",
        "print(f\"  R-squared: {r_value_igtree**2:.4f}\")\n",
        "\n",
        "# Calculate and print average increase per 10-fold increase for IGTree\n",
        "average_increase_igtree = slope_igtree * np.log(10)\n",
        "print(f\"  Average increase per 10-fold increase in training set size: {average_increase_igtree:.4f}\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "# Perform linear regression for TRIBL2\n",
        "slope_tribl2, intercept_tribl2, r_value_tribl2, p_value_tribl2, std_err_tribl2 = linregress(\n",
        "    tribl2_df['log_training_size'], tribl2_df['Token prediction accuracy']\n",
        ")\n",
        "\n",
        "# Print regression formula and values for TRIBL2\n",
        "print(f\"TRIBL2 Regression:\")\n",
        "print(f\"  Formula: Token Prediction Accuracy = {intercept_tribl2:.4f} + {slope_tribl2:.4f} * log(Training set size)\")\n",
        "print(f\"  R-value: {r_value_tribl2:.4f}\")\n",
        "print(f\"  R-squared: {r_value_tribl2**2:.4f}\")\n",
        "\n",
        "# Calculate and print average increase per 10-fold increase for TRIBL2\n",
        "average_increase_tribl2 = slope_tribl2 * np.log(10)\n",
        "print(f\"  Average increase per 10-fold increase in training set size: {average_increase_tribl2:.4f}\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Estimate token prediction accuracy at 1e+11 and 1e+12\n",
        "estimated_accuracy_igtree_1e11 = intercept_igtree + slope_igtree * np.log(1e11)\n",
        "estimated_accuracy_igtree_1e12 = intercept_igtree + slope_igtree * np.log(1e12)\n",
        "\n",
        "estimated_accuracy_tribl2_1e11 = intercept_tribl2 + slope_tribl2 * np.log(1e11)\n",
        "estimated_accuracy_tribl2_1e12 = intercept_tribl2 + slope_tribl2 * np.log(1e12)\n",
        "\n",
        "print(f\"Estimated Token Prediction Accuracy:\")\n",
        "print(f\"  IGTree at 1e+11: {estimated_accuracy_igtree_1e11:.4f}\")\n",
        "print(f\"  IGTree at 1e+12: {estimated_accuracy_igtree_1e12:.4f}\")\n",
        "print(f\"  TRIBL2 at 1e+11: {estimated_accuracy_tribl2_1e11:.4f}\")\n",
        "print(f\"  TRIBL2 at 1e+12: {estimated_accuracy_tribl2_1e12:.4f}\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "# Create new dataframes for the regression lines with a 'Model' column for legend\n",
        "regression_df_igtree = pd.DataFrame({\n",
        "    'Training set size': df['Training set size'],\n",
        "    'Token prediction accuracy': intercept_igtree + slope_igtree * np.log(df['Training set size']),\n",
        "    'Model': 'IGTree Regression'\n",
        "})\n",
        "\n",
        "regression_df_tribl2 = pd.DataFrame({\n",
        "    'Training set size': df['Training set size'],\n",
        "    'Token prediction accuracy': intercept_tribl2 + slope_tribl2 * np.log(df['Training set size']),\n",
        "    'Model': 'TRIBL2 Regression'\n",
        "})\n",
        "\n",
        "# Create the chart for the original data points with 'Models' legend\n",
        "base_chart = alt.Chart(df).mark_line(point=True).encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y='Token prediction accuracy',\n",
        "    color=alt.Color('Model', legend=alt.Legend(title='Models')), # Set legend title to 'Models'\n",
        "    tooltip=['Model', 'Training set size', 'Token prediction accuracy']\n",
        ").properties(\n",
        "    title='Token Prediction Accuracy vs. Training Set Size',\n",
        "    width=800,\n",
        "    height=450\n",
        ")\n",
        "\n",
        "base_chart = base_chart.interactive()\n",
        "\n",
        "# Create a text layer for the labels, filtering for GPT-2 and GPT-Neo\n",
        "text = alt.Chart(df).mark_text(align='left', baseline='middle', dy=0, dx=5).encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y='Token prediction accuracy',\n",
        "    text='Combined Label',\n",
        "    tooltip=['Model', 'Training set size', 'Token prediction accuracy', 'GPT-2 Label', 'GPT-Neo Label']\n",
        ").transform_filter(\n",
        "    alt.FieldOneOfPredicate(field='Model', oneOf=['GPT-2', 'GPT-Neo'])\n",
        ")\n",
        "\n",
        "\n",
        "# Create charts for the regression lines with a separate 'Regression' legend\n",
        "# Set the legend title only for the first regression line chart\n",
        "regression_line_igtree = alt.Chart(regression_df_igtree).mark_line().encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y='Token prediction accuracy',\n",
        "    color=alt.Color('Model', legend=alt.Legend(title='Regression')), # Set legend title to 'Regression'\n",
        "    strokeDash=alt.value([5, 5]), # Dashed line for IGTree Regression\n",
        "    tooltip=['Training set size', 'Token prediction accuracy', 'Model']\n",
        ")\n",
        "\n",
        "# The second regression line chart will inherit the legend properties from the first\n",
        "regression_line_tribl2 = alt.Chart(regression_df_tribl2).mark_line().encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y='Token prediction accuracy',\n",
        "    color='Model', # Do not set legend title here\n",
        "    strokeDash=alt.value([2, 2]), # Dotted line for TRIBL2 Regression\n",
        "    tooltip=['Training set size', 'Token prediction accuracy', 'Model']\n",
        ")\n",
        "\n",
        "# Combine the base chart with the text layer and the regression lines\n",
        "final_chart = base_chart + text + regression_line_igtree + regression_line_tribl2\n",
        "\n",
        "final_chart.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71c62ccd"
      },
      "source": [
        "## Plot Token Generation Latency vs. Training Set Size\n",
        "\n",
        "Generate a plot showing the relationship between Token Generation Latency and Training Set Size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2d38675"
      },
      "source": [
        "import altair as alt\n",
        "\n",
        "# Calculate Token Generation Latency\n",
        "df['Token generation latency'] = 1 / df['Tokens per second']\n",
        "\n",
        "# Define the order of models for the legend\n",
        "model_order = ['IB1-IG', 'TRIBL2', 'IGTree', 'GPT-2', 'GPT-Neo']\n",
        "\n",
        "# Create the base chart\n",
        "base_chart_latency = alt.Chart(df).encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y=alt.Y('Token generation latency', title='Token generation latency (s)'), # Use latency on the y-axis and set title\n",
        "    color=alt.Color('Model', sort=model_order, legend=alt.Legend(title='Models')), # Single legend title 'Models'\n",
        "    tooltip=['Model', 'Training set size', 'Token generation latency', 'Tokens per second'] # Update tooltip\n",
        ").properties(\n",
        "    title='Token Generation Latency vs. Training Set Size', # Update title\n",
        "    width=800,\n",
        "    height=450\n",
        ")\n",
        "\n",
        "# Add points and lines as layers to the chart\n",
        "chart_latency = base_chart_latency.mark_circle().encode( # Changed mark_point() to mark_circle() for solid points\n",
        "    # No color encoding here, inherits from base chart\n",
        "    opacity=alt.value(1) # Ensure points are visible\n",
        ") + base_chart_latency.mark_line().encode(\n",
        "    # No color encoding here, inherits from base chart\n",
        "    strokeDash=alt.StrokeDash('Model',\n",
        "                              scale=alt.Scale(domain=model_order,\n",
        "                                              range=[0, 0, 0, 0, 0])) # Solid lines for original data\n",
        ")\n",
        "\n",
        "# Create a text layer for the labels (using the original df)\n",
        "text_latency = alt.Chart(df).mark_text(align='left', baseline='middle', dy=0, dx=5).encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y='Token generation latency', # Use latency on the y-axis for text placement\n",
        "    text='Combined Label',\n",
        "    tooltip=['Model', 'Training set size', 'Token generation latency', 'GPT-2 Label', 'GPT-Neo Label'] # Update tooltip\n",
        ").transform_filter(\n",
        "    alt.FieldOneOfPredicate(field='Model', oneOf=['GPT-2', 'GPT-Neo'])\n",
        ")\n",
        "\n",
        "# Combine the chart with points and lines with the text layer\n",
        "final_chart_latency = chart_latency + text_latency\n",
        "\n",
        "final_chart_latency.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e520d8cc"
      },
      "source": [
        "## Plot kWh Usage vs. Training Set Size\n",
        "\n",
        "Generate a plot showing the relationship between kWh Usage and Training Set Size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77f2c426"
      },
      "source": [
        "import altair as alt\n",
        "\n",
        "# Carbon intensity for Germany in g/kWh\n",
        "carbon_intensity_germany = 344\n",
        "\n",
        "# Calculate CO2 emissions equivalent in grams\n",
        "df['CO2 emissions equivalent (g)'] = df['kWh usage'] * carbon_intensity_germany\n",
        "\n",
        "# Define the order of models for the legend\n",
        "model_order = ['IB1-IG', 'TRIBL2', 'IGTree', 'GPT-2', 'GPT-Neo']\n",
        "\n",
        "# Create the base chart\n",
        "base_chart_co2 = alt.Chart(df).encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y=alt.Y('CO2 emissions equivalent (g)', title='CO2 emissions equivalent (g)'), # Use CO2 emissions on the y-axis and set title\n",
        "    color=alt.Color('Model', sort=model_order, legend=alt.Legend(title='Models')), # Single legend title 'Models'\n",
        "    tooltip=['Model', 'Training set size', 'CO2 emissions equivalent (g)', 'kWh usage'] # Update tooltip\n",
        ").properties(\n",
        "    title='CO2 Emissions Equivalent vs. Training Set Size', # Update title\n",
        "    width=800,\n",
        "    height=450\n",
        ")\n",
        "\n",
        "# Add points and lines as layers to the chart\n",
        "chart_co2 = base_chart_co2.mark_circle().encode( # Changed mark_point() to mark_circle() for solid points\n",
        "    # No color encoding here, inherits from base chart\n",
        "    opacity=alt.value(1) # Ensure points are visible\n",
        ") + base_chart_co2.mark_line().encode(\n",
        "    # No color encoding here, inherits from base chart\n",
        "    strokeDash=alt.StrokeDash('Model',\n",
        "                              scale=alt.Scale(domain=model_order,\n",
        "                                              range=[0, 0, 0, 0, 0])) # Solid lines for original data\n",
        ")\n",
        "\n",
        "# Create a text layer for the labels (using the original df)\n",
        "text_co2 = alt.Chart(df).mark_text(align='left', baseline='middle', dy=0, dx=5).encode(\n",
        "    x=alt.X('Training set size', scale=alt.Scale(type='log')),\n",
        "    y='CO2 emissions equivalent (g)', # Use CO2 emissions on the y-axis for text placement\n",
        "    text='Combined Label',\n",
        "    tooltip=['Model', 'Training set size', 'CO2 emissions equivalent (g)', 'kWh usage', 'GPT-2 Label', 'GPT-Neo Label'] # Update tooltip\n",
        ").transform_filter(\n",
        "    alt.FieldOneOfPredicate(field='Model', oneOf=['GPT-2', 'GPT-Neo'])\n",
        ")\n",
        "\n",
        "# Create horizontal line layers for comparison without legend\n",
        "car_line = alt.Chart(pd.DataFrame({'y': [560]})).mark_rule(color='gray').encode(\n",
        "    y='y',\n",
        "    tooltip=['y']\n",
        ")\n",
        "\n",
        "washing_machine_line = alt.Chart(pd.DataFrame({'y': [275]})).mark_rule(color='gray').encode(\n",
        "    y='y',\n",
        "    tooltip=['y']\n",
        ")\n",
        "\n",
        "tumble_dryer_line = alt.Chart(pd.DataFrame({'y': [1000]})).mark_rule(color='gray').encode(\n",
        "    y='y',\n",
        "    tooltip=['y']\n",
        ")\n",
        "\n",
        "milk_line = alt.Chart(pd.DataFrame({'y': [2400]})).mark_rule(color='gray').encode( # Changed y-value and variable name\n",
        "    y='y',\n",
        "    tooltip=['y']\n",
        ")\n",
        "\n",
        "steel_line = alt.Chart(pd.DataFrame({'y': [1891]})).mark_rule(color='gray').encode( # Added steel line\n",
        "    y='y',\n",
        "    tooltip=['y']\n",
        ")\n",
        "\n",
        "\n",
        "# Create text layers for labels of comparison lines\n",
        "car_text = alt.Chart(pd.DataFrame({'y': [560], 'text': ['Car, 10m']})).mark_text(align='right', baseline='bottom', dx=-5, dy=-5).encode(\n",
        "    y='y',\n",
        "    text='text',\n",
        "    color=alt.value('gray')\n",
        ")\n",
        "\n",
        "washing_machine_text = alt.Chart(pd.DataFrame({'y': [275], 'text': ['Washing machine']})).mark_text(align='right', baseline='bottom', dx=-5, dy=-5).encode(\n",
        "    y='y',\n",
        "    text='text',\n",
        "    color=alt.value('gray')\n",
        ")\n",
        "\n",
        "tumble_dryer_text = alt.Chart(pd.DataFrame({'y': [1000], 'text': ['Tumble dryer']})).mark_text(align='right', baseline='bottom', dx=-5, dy=-5).encode(\n",
        "    y='y',\n",
        "    text='text',\n",
        "    color=alt.value('gray')\n",
        ")\n",
        "\n",
        "milk_text = alt.Chart(pd.DataFrame({'y': [2400], 'text': ['Milk 1l production']})).mark_text(align='right', baseline='bottom', dx=-5, dy=-5).encode( # Changed y-value and text label\n",
        "    y='y',\n",
        "    text='text',\n",
        "    color=alt.value('gray')\n",
        ")\n",
        "\n",
        "steel_text = alt.Chart(pd.DataFrame({'y': [1891], 'text': ['Steel 1kg production (furnace)']})).mark_text(align='right', baseline='bottom', dx=-5, dy=-5).encode( # Added steel text\n",
        "    y='y',\n",
        "    text='text',\n",
        "    color=alt.value('gray')\n",
        ")\n",
        "\n",
        "\n",
        "# Combine the chart with points and lines, the text layer, and the comparison lines and text\n",
        "final_chart_co2 = chart_co2 + text_co2 + car_line + washing_machine_line + tumble_dryer_line + milk_line + steel_line + car_text + washing_machine_text + tumble_dryer_text + milk_text + steel_text\n",
        "\n",
        "final_chart_co2.display()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}