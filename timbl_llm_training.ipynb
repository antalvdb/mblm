{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsvbn2rKfvrXQXVy1wQqgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antalvdb/mblm/blob/main/timbl_llm_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training a memory-based language model\n",
        "\n",
        "MBLM offers an eco-friendly alternative to neural LLMs. MBLMs rely on CPUs; no GPUs or TPUs are required. Training MBLMs is costly in terms of RAM, but not in terms of time or computing resources. This notebook exemplifies how to train an MBLM model. MBLM comes in two flavors:\n",
        "\n",
        "1.   **IB1**, k-Nearest Neighbor classification - accurate but slow and RAM-intensive;\n",
        "2.   **IGTree**, decision-tree classification based on prefix tree retrieval; fast, compact, but less accurate.\n",
        "\n",
        "This notebook assumes that you have uploaded a raw text file to Colab, or to Google Drive (moving the file to My Drive and mounting this drive). A sample text file can be downloaded from [here](https://antalvandenbosch.nl/mblm/edufineweb_train_000001-100k.txt). This file represents the first 100,000 lines of the first shard of the EduFineWeb refined web corpus by Hugging Face."
      ],
      "metadata": {
        "id": "LoOGSoMYmmCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by installing the python bindings for TiMBL, the MBLM engine. We are also installing codecarbon to track CO2 emissions."
      ],
      "metadata": {
        "id": "i8uoHuxEbSde"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vYPzhABPmkgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1525c357-0935-4acc-cb5f-52f4d0afb272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "timbl is already the newest version (6.5-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: python3-timbl in /usr/local/lib/python3.11/dist-packages (2025.5.2)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.11/dist-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from codecarbon) (8.1.8)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.21.1)\n",
            "Requirement already satisfied: psutil>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from codecarbon) (7.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.11.4)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from codecarbon) (12.0.0)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.1.0)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from codecarbon) (3.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow->codecarbon) (2.9.0.20241206)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (0.4.0)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->codecarbon) (12.570.86)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from questionary->codecarbon) (3.0.51)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->codecarbon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->codecarbon) (2.19.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.11/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "timbl is already the newest version (6.5-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: python3-timbl in /usr/local/lib/python3.11/dist-packages (2025.5.2)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.11/dist-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from codecarbon) (8.1.8)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.21.1)\n",
            "Requirement already satisfied: psutil>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from codecarbon) (7.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.11.4)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from codecarbon) (12.0.0)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.1.0)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from codecarbon) (3.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow->codecarbon) (2.9.0.20241206)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (0.4.0)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->codecarbon) (12.570.86)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from questionary->codecarbon) (3.0.51)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->codecarbon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->codecarbon) (2.19.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.11/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!apt install timbl\n",
        "!pip install python3-timbl\n",
        "!pip install codecarbon\n",
        "\n",
        "import timbl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tokenize the training data with bert-base-cased, a Hugging Face tokenizer. This is the same tokenizer we will use for other data that will be handled by our model."
      ],
      "metadata": {
        "id": "cP39_saEcAf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def process_file(input_filename):\n",
        "    # Generate the output filename by adding \"tok\" before the file extension\n",
        "    base, ext = os.path.splitext(input_filename)\n",
        "    output_filename = f\"{base}_tok{ext}\"\n",
        "\n",
        "    # Read the input file\n",
        "    with open(input_filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(lines, columns=['text'])\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # Tokenize the text\n",
        "    df['tokens'] = df['text'].apply(lambda x: tokenizer.tokenize(x))\n",
        "\n",
        "    # Write the tokens to the output file\n",
        "    with open(output_filename, 'w') as file:\n",
        "        for tokens in df['tokens']:\n",
        "            # Join the tokens list into a single string and write to the file\n",
        "            file.write(' '.join(tokens) + '\\n')\n",
        "\n",
        "    print(f\"Processed file saved as {output_filename}\")\n",
        "\n",
        "# Specify the filename directly\n",
        "filename = \"edufineweb_train_000001-100k.txt\"  # Replace with your actual filename\n",
        "input_filename = os.path.join('/content', filename)\n",
        "\n",
        "# Process the file\n",
        "process_file(input_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpVphh6bcZ87",
        "outputId": "b1242952-5476-4f3a-96d5-10fec33e2994"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file saved as /content/edufineweb_train_000001-100k_tok.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create a file with fixed-width training instances that consist of a 16-word context as features, and the next word as the class label to be predicted."
      ],
      "metadata": {
        "id": "bO5xfmXYdZ_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def generate_windowed_instances(file_path, output_file, window_size=16):\n",
        "    # Start with an empty list to accumulate tokens for each block\n",
        "    tokenized_text = []\n",
        "\n",
        "    with open(file_path, 'r') as file, open(output_file, 'w') as outfile:\n",
        "        for line in file:\n",
        "            # Strip leading/trailing whitespace from the line\n",
        "            stripped_line = line.strip()\n",
        "\n",
        "            # Check if the line is empty, indicating the end of a block\n",
        "            if not stripped_line:\n",
        "                # Process the accumulated tokens for the current block\n",
        "                if tokenized_text:\n",
        "                    # Pad the beginning of the tokenized text with underscores\n",
        "                    padded_text = [\"_\"] * window_size + tokenized_text\n",
        "\n",
        "                    # Generate and print each windowed instance for this block\n",
        "                    for i in range(window_size, len(padded_text) - 1):\n",
        "                        context = padded_text[i - window_size:i]\n",
        "                        target = padded_text[i]\n",
        "                        outfile.write(f\"{' '.join(context)} {target}\\n\")\n",
        "\n",
        "                        # Reset tokenized_text for the next block\n",
        "                        tokenized_text = []\n",
        "\n",
        "            else:\n",
        "                # Append tokens from the non-empty line to the current block\n",
        "                tokenized_text.extend(stripped_line.split())\n",
        "\n",
        "        # Process any remaining tokens after the last line\n",
        "        if tokenized_text:\n",
        "            padded_text = [\"_\"] * window_size + tokenized_text\n",
        "            for i in range(window_size, len(padded_text) - 1):\n",
        "                context = padded_text[i - window_size:i]\n",
        "                target = padded_text[i]\n",
        "                outfile.write(f\"{' '.join(context)} {target}\\n\")\n",
        "\n",
        "# Specify the input and output filenames directly\n",
        "input_filename = \"edufineweb_train_000001-100k_tok.txt\"  # Replace with your actual input filename\n",
        "output_filename = input_filename.replace(\".txt\", \".l16r0\")  # Generate output filename\n",
        "\n",
        "input_file_path = os.path.join('/content', input_filename)\n",
        "output_file_path = os.path.join('/content', output_filename)\n",
        "\n",
        "# Call the function to generate windowed instances and write to the output file\n",
        "generate_windowed_instances(input_file_path, output_file_path)"
      ],
      "metadata": {
        "id": "sT1pe4Pfduo-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we train our MBLM model with TiMBL. This can take a while and may consume high amounts of RAM.\n",
        "\n",
        "The end result is `edufineweb_train_000001-100k_tok.l16r0.ibase`, an indexed and compressed instance base suitable for TiMBL classification. In LLM terms, this is the model file that you will need for your favorite LLM inference steps.\n",
        "\n",
        "The option `-a0` means that the training set is compressed losslessly, with compression rates around 10-30%. This is the setting that implements **IB1**, k-Nearest Neighbor classification.\n",
        "\n",
        "With `-a1`, a strong lossy compression is applied, yielding higher compression levels around 90-95%, and considerably faster but less accurate inference. This is TiMBL's **IGTree** option.\n",
        "\n",
        "TiMBL is called from the Notebook shell commandline. It is wrapped inside a codecarbon CO2 emission measurement. TiMBL's quite verbose output is mixed with the equally verbose codecarbon information.\n",
        "\n"
      ],
      "metadata": {
        "id": "FhI__WMHfGIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from codecarbon import track_emissions\n",
        "\n",
        "@track_emissions(project_name=\"mblm-edufineweb_train_000001-100k_tok.l16r0\")\n",
        "def train_model():\n",
        "    !timbl -f edufineweb_train_000001-100k_tok.l16r0 -a0 +D -I edufineweb_train_000001-100k_tok.l16r0.ibase\n",
        "\n",
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1zMktq4fLB6",
        "outputId": "4ee4e0be-6c1a-469c-f6a9-4dca772b8a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 15:43:40] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 15:43:40] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 15:43:40] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 15:43:41] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 15:43:41] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 15:43:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 15:43:41] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 15:43:41] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 15:43:41] No GPU found.\n",
            "[codecarbon INFO @ 15:43:41] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 15:43:41] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 15:43:41]   Platform system: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 15:43:41]   Python version: 3.11.12\n",
            "[codecarbon INFO @ 15:43:41]   CodeCarbon version: 3.0.1\n",
            "[codecarbon INFO @ 15:43:41]   Available RAM : 12.674 GB\n",
            "[codecarbon INFO @ 15:43:41]   CPU count: 2 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 15:43:41]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 15:43:41]   GPU count: None\n",
            "[codecarbon INFO @ 15:43:41]   GPU model: None\n",
            "[codecarbon INFO @ 15:43:41] Emissions data (if any) will be saved to file /content/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2020.\n",
            "Tilburg Memory Based Learner\n",
            "Centre for Language and Speech Technology, Radboud University\n",
            "Induction of Linguistic Knowledge Research Group, Tilburg University\n",
            "CLiPS Computational Linguistics Group, University of Antwerp\n",
            "Thu May  8 15:43:41 2025\n",
            "\n",
            "Examine datafile 'edufineweb_train_000001-100k_tok.l16r0' gave the following results:\n",
            "Number of Features: 16\n",
            "InputFormat       : Columns\n",
            "\n",
            "Phase 1: Reading Datafile: edufineweb_train_000001-100k_tok.l16r0\n",
            "Start:          0 @ Thu May  8 15:43:41 2025\n",
            "Examining: 100000 @ Thu May  8 15:43:45 2025\n",
            "Examining: 200000 @ Thu May  8 15:43:48 2025\n",
            "Examining: 300000 @ Thu May  8 15:43:53 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:43:56] Energy consumed for RAM : 0.000042 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:43:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:43:56] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 15:43:56] 0.000219 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 400000 @ Thu May  8 15:43:57 2025\n",
            "Examining: 500000 @ Thu May  8 15:44:02 2025\n",
            "Examining: 600000 @ Thu May  8 15:44:07 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:44:11] Energy consumed for RAM : 0.000083 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:44:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:44:11] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 15:44:11] 0.000437 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 700000 @ Thu May  8 15:44:12 2025\n",
            "Examining: 800000 @ Thu May  8 15:44:16 2025\n",
            "Examining: 900000 @ Thu May  8 15:44:22 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:44:26] Energy consumed for RAM : 0.000125 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:44:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:44:26] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 15:44:26] 0.000656 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 1000000 @ Thu May  8 15:44:27 2025\n",
            "Examining: 1100000 @ Thu May  8 15:44:32 2025\n",
            "Examining: 1200000 @ Thu May  8 15:44:37 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:44:41] Energy consumed for RAM : 0.000167 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:44:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:44:41] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 15:44:41] 0.000875 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 1300000 @ Thu May  8 15:44:42 2025\n",
            "Examining: 1400000 @ Thu May  8 15:44:48 2025\n",
            "Examining: 1500000 @ Thu May  8 15:44:53 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:44:56] Energy consumed for RAM : 0.000208 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:44:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:44:56] Energy consumed for All CPU : 0.000886 kWh\n",
            "[codecarbon INFO @ 15:44:56] 0.001094 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 1600000 @ Thu May  8 15:44:58 2025\n",
            "Examining: 1700000 @ Thu May  8 15:45:04 2025\n",
            "Examining: 1800000 @ Thu May  8 15:45:09 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:45:11] Energy consumed for RAM : 0.000250 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:45:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:45:11] Energy consumed for All CPU : 0.001063 kWh\n",
            "[codecarbon INFO @ 15:45:11] 0.001313 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 1900000 @ Thu May  8 15:45:15 2025\n",
            "Examining: 2000000 @ Thu May  8 15:45:20 2025\n",
            "Examining: 2100000 @ Thu May  8 15:45:26 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:45:26] Energy consumed for RAM : 0.000292 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:45:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:45:26] Energy consumed for All CPU : 0.001240 kWh\n",
            "[codecarbon INFO @ 15:45:26] 0.001531 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 2200000 @ Thu May  8 15:45:31 2025\n",
            "Examining: 2300000 @ Thu May  8 15:45:37 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:45:41] Energy consumed for RAM : 0.000333 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:45:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:45:41] Energy consumed for All CPU : 0.001417 kWh\n",
            "[codecarbon INFO @ 15:45:41] 0.001750 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:45:41] 0.010761 g.CO2eq/s mean an estimation of 339.34522920213897 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 2400000 @ Thu May  8 15:45:42 2025\n",
            "Examining: 2500000 @ Thu May  8 15:45:48 2025\n",
            "Examining: 2600000 @ Thu May  8 15:45:54 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:45:56] Energy consumed for RAM : 0.000375 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:45:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:45:56] Energy consumed for All CPU : 0.001594 kWh\n",
            "[codecarbon INFO @ 15:45:56] 0.001969 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 2700000 @ Thu May  8 15:45:59 2025\n",
            "Examining: 2800000 @ Thu May  8 15:46:05 2025\n",
            "Examining: 2900000 @ Thu May  8 15:46:11 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:46:11] Energy consumed for RAM : 0.000417 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:46:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:46:11] Energy consumed for All CPU : 0.001771 kWh\n",
            "[codecarbon INFO @ 15:46:11] 0.002188 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 3000000 @ Thu May  8 15:46:17 2025\n",
            "Examining: 3100000 @ Thu May  8 15:46:22 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:46:26] Energy consumed for RAM : 0.000458 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:46:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:46:26] Energy consumed for All CPU : 0.001948 kWh\n",
            "[codecarbon INFO @ 15:46:26] 0.002406 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 3200000 @ Thu May  8 15:46:28 2025\n",
            "Examining: 3300000 @ Thu May  8 15:46:33 2025\n",
            "Examining: 3400000 @ Thu May  8 15:46:39 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:46:41] Energy consumed for RAM : 0.000500 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:46:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:46:42] Energy consumed for All CPU : 0.002125 kWh\n",
            "[codecarbon INFO @ 15:46:42] 0.002625 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 3500000 @ Thu May  8 15:46:45 2025\n",
            "Examining: 3600000 @ Thu May  8 15:46:51 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:46:56] Energy consumed for RAM : 0.000542 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:46:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:46:57] Energy consumed for All CPU : 0.002302 kWh\n",
            "[codecarbon INFO @ 15:46:57] 0.002844 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 3700000 @ Thu May  8 15:46:57 2025\n",
            "Examining: 3800000 @ Thu May  8 15:47:03 2025\n",
            "Examining: 3900000 @ Thu May  8 15:47:09 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:47:11] Energy consumed for RAM : 0.000583 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:47:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:47:12] Energy consumed for All CPU : 0.002479 kWh\n",
            "[codecarbon INFO @ 15:47:12] 0.003062 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 4000000 @ Thu May  8 15:47:14 2025\n",
            "Examining: 4100000 @ Thu May  8 15:47:20 2025\n",
            "Examining: 4200000 @ Thu May  8 15:47:26 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:47:27] Energy consumed for RAM : 0.000625 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:47:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:47:27] Energy consumed for All CPU : 0.002656 kWh\n",
            "[codecarbon INFO @ 15:47:27] 0.003281 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 4300000 @ Thu May  8 15:47:32 2025\n",
            "Examining: 4400000 @ Thu May  8 15:47:38 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:47:42] Energy consumed for RAM : 0.000667 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:47:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:47:42] Energy consumed for All CPU : 0.002833 kWh\n",
            "[codecarbon INFO @ 15:47:42] 0.003500 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:47:42] 0.010760 g.CO2eq/s mean an estimation of 339.3284895404536 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 4500000 @ Thu May  8 15:47:44 2025\n",
            "Examining: 4600000 @ Thu May  8 15:47:50 2025\n",
            "Examining: 4700000 @ Thu May  8 15:47:56 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:47:57] Energy consumed for RAM : 0.000708 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:47:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:47:57] Energy consumed for All CPU : 0.003010 kWh\n",
            "[codecarbon INFO @ 15:47:57] 0.003718 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 4800000 @ Thu May  8 15:48:02 2025\n",
            "Examining: 4900000 @ Thu May  8 15:48:08 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:48:12] Energy consumed for RAM : 0.000750 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:48:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:48:12] Energy consumed for All CPU : 0.003187 kWh\n",
            "[codecarbon INFO @ 15:48:12] 0.003937 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining: 5000000 @ Thu May  8 15:48:13 2025\n",
            "Finished:  5016728 @ Thu May  8 15:48:14 2025\n",
            "Calculating Entropy         Thu May  8 15:48:14 2025\n",
            "Lines of data     : 5016728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:48:27] Energy consumed for RAM : 0.000791 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:48:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:48:27] Energy consumed for All CPU : 0.003365 kWh\n",
            "[codecarbon INFO @ 15:48:27] 0.004156 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DB Entropy        : 10.739261\n",
            "Number of Classes : 26915\n",
            "\n",
            "Feats\tVals\tInfoGain\tGainRatio\n",
            "    1  26915\t2.1906111\t0.20398148\n",
            "    2  26915\t2.1920201\t0.20411270\n",
            "    3  26915\t2.1954564\t0.20443265\n",
            "    4  26915\t2.1958033\t0.20446497\n",
            "    5  26915\t2.2009414\t0.20494344\n",
            "    6  26915\t2.2021521\t0.20505616\n",
            "    7  26915\t2.2081435\t0.20561406\n",
            "    8  26915\t2.2123939\t0.20600985\n",
            "    9  26915\t2.2217645\t0.20688242\n",
            "   10  26915\t2.2388949\t0.20847754\n",
            "   11  26915\t2.2593096\t0.21037848\n",
            "   12  26915\t2.2870857\t0.21296491\n",
            "   13  26915\t2.3497464\t0.21879964\n",
            "   14  26915\t2.4916539\t0.23201355\n",
            "   15  26915\t2.7844700\t0.25927949\n",
            "   16  26915\t3.7981671\t0.35367119\n",
            "\n",
            "Preparation took 286 seconds, 345 milliseconds and 785 microseconds\n",
            "Feature Permutation based on GainRatio/Values :\n",
            "< 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1 >\n",
            "Phase 2: Building multi index on Datafile: edufineweb_train_000001-100k_tok.l16r0\n",
            "Start:          0 @ Thu May  8 15:48:28 2025\n",
            "Indexing:  100000 @ Thu May  8 15:48:30 2025\n",
            "Indexing:  200000 @ Thu May  8 15:48:32 2025\n",
            "Indexing:  300000 @ Thu May  8 15:48:35 2025\n",
            "Indexing:  400000 @ Thu May  8 15:48:37 2025\n",
            "Indexing:  500000 @ Thu May  8 15:48:39 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:48:42] Energy consumed for RAM : 0.000833 kWh. RAM Power : 10.0 W\n",
            "[codecarbon INFO @ 15:48:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 15:48:42] Energy consumed for All CPU : 0.003542 kWh\n",
            "[codecarbon INFO @ 15:48:42] 0.004375 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexing:  600000 @ Thu May  8 15:48:42 2025\n",
            "Indexing:  700000 @ Thu May  8 15:48:44 2025\n"
          ]
        }
      ]
    }
  ]
}